<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html>
<head>
  <meta http-equiv="content-type" content="text/html; charset=Shift_JIS">
  <title>ê¸å`ë„êî</title>
</head>
<body>
<table cellpadding="2" cellspacing="2" border="1"
 style="text-align: left; width: 100%;">
  <tbody>
    <tr>
      <td style="vertical-align: top;" rowspan="1" colspan="4"><span
 style="font-weight: bold;">ê¸å`ë„êî</span><br>
Linear algebra functions in Julia are largely implemented by calling
functions from LAPACK. Sparse factorizations call functions from
SuiteSparse.<br>
      </td>
    </tr>
    <tr>
      <td style="vertical-align: top; font-weight: bold;">èëéÆ<br>
      </td>
      <td style="vertical-align: top; font-weight: bold;">ã@î\<br>
      </td>
      <td style="vertical-align: top; font-weight: bold;">ó·ëË<br>
      </td>
      <td style="vertical-align: top; font-weight: bold;">åãâ <br>
      </td>
    </tr>
    <tr>
      <td style="vertical-align: top;">*(A, B) </td>
      <td style="vertical-align: top;">Matrix multiplication<br>
      </td>
      <td style="vertical-align: top;">*([1 2;3 5], [2 1;3 2]) </td>
      <td style="vertical-align: top;">2x2 Array{Int64,2}:<br>
&nbsp; 8&nbsp;&nbsp; 5<br>
&nbsp;21&nbsp; 13<br>
      </td>
    </tr>
    <tr>
      <td style="vertical-align: top;">\(A, B) </td>
      <td style="vertical-align: top;">Matrix division using a
polyalgorithm. For input
matrices A and B, the result X is such that A*X == B when A is square.
The solver that is used depends upon the structure of A. A direct
solver is used for upper or lower triangular A. For Hermitian A
(equivalent to symmetric A for non-complex A) the BunchKaufman
factorization is used. Otherwise an LU factorization is used. For
rectangular A the result is the minimum-norm least squares solution
computed by a pivoted QR factorization of A and a rank estimate of A
based on the R factor.<br>
When A is sparse, a similar polyalgorithm is used.
For indefinite matrices, the LDLt factorization does not use pivoting
during the numerical factorization and therefore the procedure can fail
even for invertible matrices.<br>
      </td>
      <td style="vertical-align: top;">\([1 2;3 5], [2 1;3 2]) </td>
      <td style="vertical-align: top;">2x2 Array{Float64,2}:<br>
&nbsp;-4.0&nbsp; -1.0<br>
&nbsp; 3.0&nbsp;&nbsp; 1.0<br>
      <br>
      </td>
    </tr>
    <tr>
      <td style="vertical-align: top;">dot(x, y)<br>
&#8901;(x, y) </td>
      <td style="vertical-align: top;">Compute the dot product. For
complex vectors, the
first vector is conjugated.<br>
      </td>
      <td style="vertical-align: top;">dot(2, 5) </td>
      <td style="vertical-align: top;">10<br>
      </td>
    </tr>
    <tr>
      <td style="vertical-align: top;">vecdot(x, y) </td>
      <td style="vertical-align: top;">For any iterable containers x
and y (including
arrays of any dimension) of numbers (or any element type for which dot
is defined), compute the Euclidean dot product (the sum of
dot(x[i],y[i])) as if they were vectors.<br>
ì‡êœ<br>
      </td>
      <td style="vertical-align: top;">vecdot(vec([5, 3]),vec([3,2]))<br>
      <br>
      <br>
      </td>
      <td style="vertical-align: top;">21 </td>
    </tr>
    <tr>
      <td style="vertical-align: top;">cross(x, y)<br>
Å~(x, y) </td>
      <td style="vertical-align: top;">Compute the cross product of two
3-vectors.<br>
äOêœ<br>
      </td>
      <td style="vertical-align: top;">cross(vec([5,
3,4]),vec([3,2,1])) </td>
      <td style="vertical-align: top;">3-element Array{Int64,1}:<br>
&nbsp;-5<br>
&nbsp; 7<br>
&nbsp; 1<br>
      </td>
    </tr>
    <tr>
      <td style="vertical-align: top;">factorize(A) </td>
      <td style="vertical-align: top;">Compute a convenient
factorization (including LU,
Cholesky, Bunch-Kaufman, LowerTriangular, UpperTriangular) of A, based
upon the type of the input matrix. The return value can then be reused
for efficient solving of multiple systems. For example: A=factorize(A);
x=A\b; y=A\C.<br>
      </td>
      <td style="vertical-align: top;">factorize([1 2;3 4]) </td>
      <td style="vertical-align: top;">Base.LinAlg.LU{Float64,Tridiagonal{Float64}}(2x2
Tridiagonal{Float64}:<br>
&nbsp;1.0&nbsp;&nbsp; 2.0<br>
&nbsp;3.0&nbsp; -2.0,[1,2],0)<br>
      </td>
    </tr>
    <tr>
      <td style="vertical-align: top;">full(F)<br>
      </td>
      <td style="vertical-align: top;"> Reconstruct the matrix A from
the factorization F=factorize(A)</td>
      <td style="vertical-align: top;">full([1 3;4 6]) </td>
      <td style="vertical-align: top;">2x2 Array{Int64,2}:<br>
&nbsp;1&nbsp; 3<br>
&nbsp;4&nbsp; 6<br>
      </td>
    </tr>
    <tr>
      <td style="vertical-align: top;">lu(A) <br>
Å® L, U, p </td>
      <td style="vertical-align: top;">Compute the LU factorization of
A, such that A[p,:]
= L*U.<br>
      </td>
      <td style="vertical-align: top;">lu([1 4;4 6]) </td>
      <td style="vertical-align: top;">(<br>
2x2 Array{Float64,2}:<br>
&nbsp;1.0&nbsp;&nbsp; 0.0<br>
&nbsp;0.25&nbsp; 1.0,<br>
2x2 Array{Float64,2}:<br>
&nbsp;4.0&nbsp; 6.0<br>
&nbsp;0.0&nbsp; 2.5,<br>
[2,1])<br>
      </td>
    </tr>
    <tr>
      <td style="vertical-align: top;">lufact(A[, pivot=Val{true}]) Å® F<br>
      </td>
      <td style="vertical-align: top;">Compute the LU factorization of
A. The return type of F depends on the type of A. In most cases, if A
is a subtype S of AbstractMatrix with an element type T supporting +,
-, * and / the return type is LU{T,S{T}}. If pivoting is chosen
(default) the element type should also support abs and &lt;. When A is
sparse and have element of type Float32, Float64, Complex{Float32}, or
Complex{Float64} the return type is UmfpackLU. Some examples are shown
in the table below.<br>
      <table cellpadding="2" cellspacing="2" border="1"
 style="text-align: left; width: 80%; margin-left: auto; margin-right: auto;">
        <tbody>
          <tr>
            <td style="vertical-align: top; font-weight: bold;">Type of
input A</td>
            <td style="vertical-align: top; font-weight: bold;">Type of
output F</td>
            <td style="vertical-align: top; font-weight: bold;">Relationship
between F and A</td>
          </tr>
          <tr>
            <td style="vertical-align: top;">Matrix() </td>
            <td style="vertical-align: top;">LU</td>
            <td style="vertical-align: top;"> F[:L]*F[:U] == A[F[:p], :]</td>
          </tr>
          <tr>
            <td style="vertical-align: top;">Tridiagonal() &nbsp; <br>
            </td>
            <td style="vertical-align: top;"> LU{T,Tridiagonal{T}}
&nbsp; <br>
            </td>
            <td style="vertical-align: top;"> F[:L]*F[:U] == A[F[:p], :]</td>
          </tr>
          <tr>
            <td style="vertical-align: top;">SparseMatrixCSC()&nbsp; <br>
            </td>
            <td style="vertical-align: top;">UmfpackLU </td>
            <td style="vertical-align: top;">F[:L]*F[:U] == (F[:Rs] .*
A)[F[:p], F[:q]]</td>
          </tr>
        </tbody>
      </table>
The individual components of the factorization F can be accessed by
indexing:<br>
      <table cellpadding="2" cellspacing="2" border="1"
 style="text-align: left; width: 80%; margin-left: auto; margin-right: auto;">
        <tbody>
          <tr>
            <td style="vertical-align: top; font-weight: bold;">Component
            </td>
            <td style="vertical-align: top; font-weight: bold;">Description
            </td>
            <td style="vertical-align: top; font-weight: bold;">LU&nbsp;
            <br>
            </td>
            <td style="vertical-align: top; font-weight: bold;">LU{T,Tridiagonal{T}}
&nbsp; <br>
            </td>
            <td style="vertical-align: top; font-weight: bold;">UmfpackLU</td>
          </tr>
          <tr>
            <td style="vertical-align: top;">F[:L] </td>
            <td style="vertical-align: top;">L (lower triangular) part
of LU &nbsp; <br>
            </td>
            <td style="vertical-align: top;">&#10003;</td>
            <td style="vertical-align: top;">&#10003;</td>
            <td style="vertical-align: top;">&#10003;</td>
          </tr>
          <tr>
            <td style="vertical-align: top;">F[:U]&nbsp; <br>
            </td>
            <td style="vertical-align: top;">U (upper triangular) part
of LU</td>
            <td style="vertical-align: top;">&#10003; &nbsp; <br>
            </td>
            <td style="vertical-align: top;">&#10003; </td>
            <td style="vertical-align: top;">&#10003;</td>
          </tr>
          <tr>
            <td style="vertical-align: top;">F[:p]</td>
            <td style="vertical-align: top;">&nbsp;&nbsp;&nbsp;&nbsp;
(right) permutation Vector &nbsp;&nbsp; <br>
            </td>
            <td style="vertical-align: top;"> &#10003;</td>
            <td style="vertical-align: top;">&#10003;<br>
            </td>
            <td style="vertical-align: top;">&#10003;</td>
          </tr>
          <tr>
            <td style="vertical-align: top;">F[:P] </td>
            <td style="vertical-align: top;">(right) permutation Matrix
            </td>
            <td style="vertical-align: top;">&#10003; <br>
            </td>
            <td style="vertical-align: top;">&#10003;</td>
            <td style="vertical-align: top;"><br>
            </td>
          </tr>
          <tr>
            <td style="vertical-align: top;">F[:q]&nbsp; <br>
            </td>
            <td style="vertical-align: top;">left permutation Vector</td>
            <td style="vertical-align: top;"><br>
            </td>
            <td style="vertical-align: top;"><br>
            </td>
            <td style="vertical-align: top;">&#10003;</td>
          </tr>
          <tr>
            <td style="vertical-align: top;">F[:Rs]&nbsp; <br>
            </td>
            <td style="vertical-align: top;"> Vector of scaling
factors&nbsp; <br>
            </td>
            <td style="vertical-align: top;"><br>
            </td>
            <td style="vertical-align: top;"><br>
            </td>
            <td style="vertical-align: top;">&#10003;<br>
            </td>
          </tr>
          <tr>
            <td style="vertical-align: top;">F[:(:)] </td>
            <td style="vertical-align: top;">(L,U,p,q,Rs) components </td>
            <td style="vertical-align: top;"><br>
            </td>
            <td style="vertical-align: top;"><br>
            </td>
            <td style="vertical-align: top;">&#10003;<br>
            </td>
          </tr>
        </tbody>
      </table>
      <br>
      <table cellpadding="2" cellspacing="2" border="1"
 style="text-align: left; width: 80%;">
        <tbody>
          <tr>
            <td style="vertical-align: top;">Supported function </td>
            <td style="vertical-align: top;"> LU</td>
            <td style="vertical-align: top;">LU{T,Tridiagonal{T}}&nbsp;
            <br>
            </td>
            <td style="vertical-align: top;">UmfpackLU</td>
          </tr>
          <tr>
            <td style="vertical-align: top;">/</td>
            <td style="vertical-align: top;">&#10003;</td>
            <td style="vertical-align: top;"><br>
            </td>
            <td style="vertical-align: top;"><br>
            </td>
          </tr>
          <tr>
            <td style="vertical-align: top;">\<br>
            </td>
            <td style="vertical-align: top;">&#10003;<br>
            </td>
            <td style="vertical-align: top;">&#10003;<br>
            </td>
            <td style="vertical-align: top;">&#10003;<br>
            </td>
          </tr>
          <tr>
            <td style="vertical-align: top;">cond</td>
            <td style="vertical-align: top;">&#10003;<br>
            </td>
            <td style="vertical-align: top;"><br>
            </td>
            <td style="vertical-align: top;">&#10003;<br>
            </td>
          </tr>
          <tr>
            <td style="vertical-align: top;">det </td>
            <td style="vertical-align: top;">&#10003;<br>
            </td>
            <td style="vertical-align: top;">&#10003;<br>
            </td>
            <td style="vertical-align: top;">&#10003;<br>
            </td>
          </tr>
          <tr>
            <td style="vertical-align: top;">logdet</td>
            <td style="vertical-align: top;">&#10003;<br>
            </td>
            <td style="vertical-align: top;">&#10003;<br>
            </td>
            <td style="vertical-align: top;"><br>
            </td>
          </tr>
          <tr>
            <td style="vertical-align: top;">logabsdet</td>
            <td style="vertical-align: top;">&#10003;<br>
            </td>
            <td style="vertical-align: top;">&#10003;<br>
            </td>
            <td style="vertical-align: top;"><br>
            </td>
          </tr>
          <tr>
            <td style="vertical-align: top;">size</td>
            <td style="vertical-align: top;">&#10003;<br>
            </td>
            <td style="vertical-align: top;">&#10003;<br>
            </td>
            <td style="vertical-align: top;"><br>
            </td>
          </tr>
        </tbody>
      </table>
      <br>
      </td>
      <td style="vertical-align: top;">lufact([1 4;4 6]) </td>
      <td style="vertical-align: top;">Base.LinAlg.LU{Float64,Array{Float64,2}}(2x2
Array{Float64,2}:<br>
&nbsp;1.0&nbsp;&nbsp;&nbsp; 4.0<br>
&nbsp;4.0&nbsp; -10.0,[1,2],0)<br>
      <br>
      </td>
    </tr>
    <tr>
      <td style="vertical-align: top;">lufact!(A) Å® LU</td>
      <td style="vertical-align: top;">lufact! is the same as lufact(),
but saves space by overwriting the input A, instead of creating a copy.
For sparse A the nzval field is not overwritten but the index fields,
colptr and rowval are decremented in place, converting from 1-based
indices to 0-based indices.<br>
      </td>
      <td style="vertical-align: top;">lufact!([2 3]) </td>
      <td style="vertical-align: top;">Base.LinAlg.LU{Int64,Array{Int64,2}}(1x2
Array{Int64,2}:<br>
&nbsp;2&nbsp; 3,[1],0)<br>
      </td>
    </tr>
    <tr>
      <td style="vertical-align: top;">chol(A[, LU]) Å® F </td>
      <td style="vertical-align: top;">Compute the Cholesky
factorization of a symmetric
positive definite matrix A and return the matrix F. If LU is Val{:U}
(Upper), F is of type UpperTriangular and A = F'*F. If LU is Val{:L}
(Lower), F is of type LowerTriangular and A = F*F'. LU defaults to
Val{:U}.<br>
      </td>
      <td style="vertical-align: top;">chol([1 2;2 5]) </td>
      <td style="vertical-align: top;">2x2
UpperTriangular{Float64,Array{Float64,2}}:<br>
&nbsp;1.0&nbsp; 2.0<br>
&nbsp;0.0&nbsp; 1.0<br>
      </td>
    </tr>
    <tr>
      <td style="vertical-align: top;">cholfact(A,
[LU=:U[,pivot=Val{false}]][;tol=-1.0]) <br>
Å® Cholesky </td>
      <td style="vertical-align: top;">Compute the Cholesky
factorization of a dense
symmetric positive (semi)definite matrix A and return either a Cholesky
if pivot==Val{false} or CholeskyPivoted if pivot==Val{true}. LU may be
:L for using the lower part or :U for the upper part. The default is to
use :U. The triangular matrix can be obtained from the factorization F
with: F[:L] and F[:U]. The following functions are available for
Cholesky objects: size, \, inv, det. For CholeskyPivoted there is also
defined a rank. If pivot==Val{false} a PosDefException exception is
thrown in case the matrix is not positive definite. The argument tol
determines the tolerance for determining the rank. For negative values,
the tolerance is the machine precision.<br>
      </td>
      <td style="vertical-align: top;">cholfact([2 3;4 6]) </td>
      <td style="vertical-align: top;">Base.LinAlg.Cholesky{Float64,Array{Float64,2}}
with factor:<br>
2x2 UpperTriangular{Float64,Array{Float64,2}}:<br>
&nbsp;1.41421&nbsp; 2.12132<br>
&nbsp;0.0&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 1.22474<br>
      <br>
      </td>
    </tr>
    <tr>
      <td style="vertical-align: top;">cholfact(A; shift=0, perm=Int[])
      <br>
Å® CHOLMOD.Factor </td>
      <td style="vertical-align: top;">Compute the Cholesky
factorization of a sparse
positive definite matrix A. A fill-reducing permutation is used. F =
cholfact(A) is most frequently used to solve systems of equations with
F\b, but also the methods diag, det, logdet are defined for F. You can
also extract individual factors from F, using F[:L]. However, since
pivoting is on by default, the factorization is internally represented
as A == P'*L*L'*P with a permutation matrix P; using just L without
accounting for P will give incorrect answers. To include the effects of
permutation, itÅfs typically preferable to extact ÅgcombinedÅh factors
like PtL = F[:PtL] (the equivalent of P'*L) and LtP = F[:UP] (the
equivalent of L'*P).<br>
&nbsp;&nbsp;&nbsp; Setting optional shift keyword argument computes the
factorization of A+shift*I instead of A. If the perm argument is
nonempty, it should be a permutation of 1:size(A,1) giving the ordering
to use (instead of CHOLMODÅfs default AMD ordering).<br>
&nbsp;&nbsp;&nbsp; The function calls the C library CHOLMOD and many
other functions from the library are wrapped but not exported.<br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
    </tr>
    <tr>
      <td style="vertical-align: top;">cholfact!(A [,LU=:U
[,pivot=Val{false}]][;tol=-1.0]) <br>
Å® Cholesky </td>
      <td style="vertical-align: top;">cholfact! is the same as
cholfact(), but saves space
by overwriting the input A, instead of creating a copy. cholfact! can
also reuse the symbolic factorization from a different matrix F with
the same structure when used as: cholfact!(F::CholmodFactor, A).<br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
    </tr>
    <tr>
      <td style="vertical-align: top;">ldltfact(::SymTridiagonal) <br>
Å®
LDLt </td>
      <td style="vertical-align: top;">Compute an LDLt factorization of
a real symmetric
tridiagonal matrix such that A = L*Diagonal(d)*L' where L is a unit
lower triangular matrix and d is a vector. The main use of an LDLt
factorization F = ldltfact(A) is to solve the linear system of
equations Ax = b with F\b.<br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
    </tr>
    <tr>
      <td style="vertical-align: top;">ldltfact(::Union{SparseMatrixCSC,
Symmetric{Float64,
SparseMatrixCSC{Flaot64, SuiteSparse_long}},
Hermitian{Complex{Float64}, SparseMatrixCSC{Complex{Float64},
SuiteSparse_long}}}; shift=0, perm=Int[]) <br>
Å® CHOLMOD.Factor </td>
      <td style="vertical-align: top;">Compute the LDLt factorization
of a sparse symmetric
or Hermitian matrix. A fill-reducing permutation is used. F =
ldltfact(A) is most frequently used to solve systems of equations A*x =
b with F\b, but also the methods diag, det, logdet are defined for F.
You can also extract individual factors from F, using F[:L]. However,
since pivoting is on by default, the factorization is internally
represented as A == P'*L*D*L'*P with a permutation matrix P; using just
L without accounting for P will give incorrect answers. To include the
effects of permutation, itÅfs typically preferable to extact ÅgcombinedÅh
factors like PtL = F[:PtL] (the equivalent of P'*L) and LtP = F[:UP]
(the equivalent of L'*P). The complete list of supported factors is :L,
:PtL, :D, :UP, :U, :LD, :DU, :PtLD, :DUP.<br>
&nbsp;&nbsp;&nbsp; Setting optional shift keyword argument computes the
factorization of A+shift*I instead of A. If the perm argument is
nonempty, it should be a permutation of 1:size(A,1) giving the ordering
to use (instead of CHOLMODÅfs default AMD ordering).<br>
&nbsp;&nbsp;&nbsp; The function calls the C library CHOLMOD and many
other functions from the library are wrapped but not exported.<br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
    </tr>
    <tr>
      <td style="vertical-align: top;">ldltfact!(::SymTridiagonal) <br>
Å®
LDLt </td>
      <td style="vertical-align: top;">Same as ldltfact, but saves
space by overwriting the
input A, instead of creating a copy.<br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
    </tr>
    <tr>
      <td style="vertical-align: top;">qr(A[,
pivot=Val{false}][;thin=true]) <br>
Å® Q, R, [p] </td>
      <td style="vertical-align: top;">Compute the (pivoted) QR
factorization of A such
that either A = Q*R or A[:,p] = Q*R. Also see qrfact. The default is to
compute a thin factorization. Note that R is not extended with zeros
when the full Q is requested.<br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
    </tr>
    <tr>
      <td style="vertical-align: top;">qrfact(A[, pivot=Val{false}]) <br>
Å®
F </td>
      <td style="vertical-align: top;">Computes the QR factorization of
A. The return type
of F depends on the element type of A and whether pivoting is specified
(with pivot==Val{true}).<br>
      <table cellpadding="2" cellspacing="2" border="1"
 style="text-align: left; width: 80%; margin-left: auto; margin-right: auto;">
        <tbody>
          <tr>
            <td style="vertical-align: top;">Return type</td>
            <td style="vertical-align: top;">eltype(A) </td>
            <td style="vertical-align: top;">pivot</td>
            <td style="vertical-align: top;">Relationship between F and
A</td>
          </tr>
          <tr>
            <td style="vertical-align: top;">QR</td>
            <td style="vertical-align: top;">not BlasFloat </td>
            <td style="vertical-align: top;">either </td>
            <td style="vertical-align: top;">A==F[:Q]*F[:R]</td>
          </tr>
          <tr>
            <td style="vertical-align: top;">QRCompactWY </td>
            <td style="vertical-align: top;">BlasFloat </td>
            <td style="vertical-align: top;">Val{false}</td>
            <td style="vertical-align: top;">A==F[:Q]*F[:R]</td>
          </tr>
          <tr>
            <td style="vertical-align: top;">QRPivoted&nbsp; <br>
            </td>
            <td style="vertical-align: top;">BlasFloat &nbsp; <br>
            </td>
            <td style="vertical-align: top;">Val{true}&nbsp; <br>
            </td>
            <td style="vertical-align: top;">A[:,F[:p]]==F[:Q]*F[:R]</td>
          </tr>
        </tbody>
      </table>
BlasFloat refers to any of: Float32, Float64, Complex64 or Complex128.<br>
The individual components of the factorization F can be accessed by
indexing:<br>
      <table cellpadding="2" cellspacing="2" border="1"
 style="text-align: left; width: 80%; margin-left: auto; margin-right: auto;">
        <tbody>
          <tr>
            <td style="vertical-align: top; font-weight: bold;">Component&nbsp;
            <br>
            </td>
            <td style="vertical-align: top; font-weight: bold;">Description</td>
            <td style="vertical-align: top; font-weight: bold;">QR</td>
            <td style="vertical-align: top; font-weight: bold;">QRCompactWY
            </td>
            <td style="vertical-align: top; font-weight: bold;">QRPivoted</td>
          </tr>
          <tr>
            <td style="vertical-align: top;">F[:Q] </td>
            <td style="vertical-align: top;">Q (orthogonal/unitary)
part of QR</td>
            <td style="vertical-align: top;">&#10003; (QRPackedQ)</td>
            <td style="vertical-align: top;">&#10003; (QRCompactWYQ)</td>
            <td style="vertical-align: top;">&#10003; (QRPackedQ)</td>
          </tr>
          <tr>
            <td style="vertical-align: top;">F[:R] </td>
            <td style="vertical-align: top;"> R (upper right
triangular) part of QR</td>
            <td style="vertical-align: top;">&#10003; &nbsp;&nbsp; <br>
            </td>
            <td style="vertical-align: top;"> &#10003; <br>
            </td>
            <td style="vertical-align: top;">&#10003;<br>
            </td>
          </tr>
          <tr>
            <td style="vertical-align: top;">F[:p] </td>
            <td style="vertical-align: top;"> pivot Vector&nbsp; <br>
            </td>
            <td style="vertical-align: top;"><br>
            </td>
            <td style="vertical-align: top;"><br>
            </td>
            <td style="vertical-align: top;">&#10003;<br>
            </td>
          </tr>
          <tr>
            <td style="vertical-align: top;">F[:P]</td>
            <td style="vertical-align: top;"> (pivot) permutation
Matrix </td>
            <td style="vertical-align: top;"><br>
            </td>
            <td style="vertical-align: top;"><br>
            </td>
            <td style="vertical-align: top;">&#10003;<br>
            </td>
          </tr>
        </tbody>
      </table>
The following functions are available for the QR objects: size, \. When
A is rectangular, \ will return a least squares solution and if the
solution is not unique, the one with smallest norm is returned.<br>
Multiplication with respect to either thin or full Q is allowed, i.e.
both F[:Q]*F[:R] and F[:Q]*A are supported. A Q matrix can be converted
into a regular matrix with full() which has a named argument thin.<br>
Note<br>
qrfact returns multiple types because LAPACK uses several
representations that minimize the memory storage requirements of
products of Householder elementary reflectors, so that the Q and R
matrices can be stored compactly rather as two separate dense matrices.<br>
The data contained in QR or QRPivoted can be used to construct the
QRPackedQ type, which is a compact representation of the rotation
matrix:<br>
Q=&#8719;i=1min(m,n)(IÅ|É—ivivTi)<br>
Q=&#8719;i=1min(m,n)(IÅ|É—iviviT)<br>
where É—iÉ—i is the scale factor and vivi is the projection vector
associated with the ithith Householder elementary reflector.<br>
The data contained in QRCompactWY can be used to construct the
QRCompactWYQ type, which is a compact representation of the rotation
matrix<br>
Q=I+YTYT<br>
Q=I+YTYT<br>
where Y is mÅ~rmÅ~r lower trapezoidal and T is rÅ~rrÅ~r upper triangular.
The compact WY representation [Schreiber1989] is not to be confused
with the older, WY representation [Bischof1987]. (The LAPACK
documentation uses V in lieu of Y.)<br>
[Bischof1987] &nbsp;&nbsp;&nbsp; (1, 2) C Bischof and C Van Loan, ÅgThe
WY representation for products of Householder matricesÅh, SIAM J Sci
Stat Comput 8 (1987), s2-s13. doi:10.1137/0908009<br>
[Schreiber1989] &nbsp;&nbsp;&nbsp; R Schreiber and C Van Loan, ÅgA
storage-efficient WY representation for products of Householder
transformationsÅh, SIAM J Sci Stat Comput 10 (1989), 53-57.
doi:10.1137/0910005<br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
    </tr>
    <tr>
      <td style="vertical-align: top;">qrfact(A) Å® SPQR.Factorization </td>
      <td style="vertical-align: top;">Compute the QR factorization of
a sparse matrix A. A
fill-reducing permutation is used. The main application of this type is
to solve least squares problems with \. The function calls the C
library SPQR and a few additional functions from the library are
wrapped but not exported.<br>
      </td>
      <td style="vertical-align: top;">qrfact([2 3]) </td>
      <td style="vertical-align: top;">Base.LinAlg.QRCompactWY{Float64,Array{Float64,2}}(1x2
Array{Float64,2}:<br>
&nbsp;2.0&nbsp; 3.0,1x1 Array{Float64,2}:<br>
&nbsp;0.0)<br>
      </td>
    </tr>
    <tr>
      <td style="vertical-align: top;">qrfact!(A[, pivot=Val{false}]) </td>
      <td style="vertical-align: top;">qrfact! is the same as qrfact()
when A is a subtype
of StridedMatrix, but saves space by overwriting the input A, instead
of creating a copy.<br>
      </td>
      <td style="vertical-align: top;">qrfact!([2 6]) </td>
      <td style="vertical-align: top;">Base.LinAlg.QR{Int64,Array{Int64,2}}(1x2
Array{Int64,2}:<br>
&nbsp;2&nbsp; 6,[0])<br>
      </td>
    </tr>
    <tr>
      <td style="vertical-align: top;">full(QRCompactWYQ[, thin=true]) <br>
Å® Matrix </td>
      <td style="vertical-align: top;">Converts an orthogonal or
unitary matrix stored as a
QRCompactWYQ object, i.e. in the compact WY format [Bischof1987], to a
dense matrix.<br>
Optionally takes a thin Boolean argument, which if
true omits the columns that span the rows of R in the QR factorization
that are zero. The resulting matrix is the Q in a thin QR factorization
(sometimes called the reduced QR factorization). If false, returns a Q
that spans all rows of R in its corresponding QR factorization.<br>
      </td>
      <td style="vertical-align: top;">full([2 5]) </td>
      <td style="vertical-align: top;">1x2 Array{Int64,2}:<br>
&nbsp;2&nbsp; 5<br>
      </td>
    </tr>
    <tr>
      <td style="vertical-align: top;">bkfact(A) <br>
Å®BunchKaufman</td>
      <td style="vertical-align: top;">Compute the Bunch-Kaufman
[Bunch1977] factorization of a real symmetric or complex Hermitian
matrix A and return a BunchKaufman object. The following functions are
available for BunchKaufman objects: size, \, inv, issym, ishermitian.<br>
[Bunch1977] &nbsp;&nbsp;&nbsp; J R Bunch and L Kaufman, Some stable
methods for calculating inertia and solving symmetric linear systems,
Mathematics of Computation 31:137 (1977), 163-179. url.<br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
    </tr>
    <tr>
      <td style="vertical-align: top;">bkfact!(A) Å® BunchKaufman</td>
      <td style="vertical-align: top;">bkfact! is the same as bkfact(),
but saves space by overwriting the input A, instead of creating a copy.<br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
    </tr>
    <tr>
      <td style="vertical-align: top;">eig(A,[irange,][vl,][vu,][permute=true,][scale=true])
Å® D, V</td>
      <td style="vertical-align: top;">Computes eigenvalues and
eigenvectors of A. See eigfact() for details on the balance keyword
argument.<br>
eig is a wrapper around eigfact(), extracting all parts of the
factorization to a tuple; where possible, using eigfact() is
recommended.<br>
      </td>
      <td style="vertical-align: top;">eig([1.0 0.0 0.0; 0.0 3.0 0.0;
0.0 0.0 18.0])<br>
&nbsp;&nbsp;&nbsp; <br>
      </td>
      <td style="vertical-align: top;">([1.0,3.0,18.0],<br>
3x3 Array{Float64,2}:<br>
&nbsp;&nbsp;&nbsp;&nbsp; 1.0&nbsp; 0.0&nbsp; 0.0<br>
&nbsp;&nbsp;&nbsp;&nbsp; 0.0&nbsp; 1.0&nbsp; 0.0<br>
&nbsp;&nbsp;&nbsp;&nbsp; 0.0&nbsp; 0.0&nbsp; 1.0)</td>
    </tr>
    <tr>
      <td style="vertical-align: top;">eig(A, B) <br>
Å® D, V </td>
      <td style="vertical-align: top;">Computes generalized eigenvalues
and vectors of A
with respect to B.<br>
&nbsp;&nbsp;&nbsp; eig is a wrapper around eigfact(), extracting all
parts of the factorization to a tuple; where possible, using eigfact()
is recommended.<br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
    </tr>
    <tr>
      <td style="vertical-align: top;">eigvals(A,[irange,][vl,][vu]) <br>
Å® values </td>
      <td style="vertical-align: top;">Returns the eigenvalues of A. If
A is Symmetric,
Hermitian or SymTridiagonal, it is possible to calculate only a subset
of the eigenvalues by specifying either a UnitRange irange covering
indices of the sorted eigenvalues, or a pair vl and vu for the lower
and upper boundaries of the eigenvalues.<br>
&nbsp;&nbsp;&nbsp; For general non-symmetric matrices it is possible to
specify how the matrix is balanced before the eigenvector calculation.
The option permute=true permutes the matrix to become closer to upper
triangular, and scale=true scales the matrix by its diagonal elements
to make rows and columns moreequal in norm. The default is true for
both options.<br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
    </tr>
    <tr>
      <td style="vertical-align: top;">eigvals!(A,[irange,][vl,][vu]) Å®
values </td>
      <td style="vertical-align: top;">Same as eigvals, but saves space
by overwriting the
input A (and B), instead of creating a copy.<br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
    </tr>
    <tr>
      <td style="vertical-align: top;">eigmax(A) </td>
      <td style="vertical-align: top;">Returns the largest eigenvalue
of A.<br>
      </td>
      <td style="vertical-align: top;">eigmax([2 4;4 6]) </td>
      <td style="vertical-align: top;">8.47213595499958<br>
      </td>
    </tr>
    <tr>
      <td style="vertical-align: top;">eigmin(A) </td>
      <td style="vertical-align: top;">Returns the smallest eigenvalue
of A.<br>
      </td>
      <td style="vertical-align: top;">eigmin([2 4;4 6]) </td>
      <td style="vertical-align: top;">-0.4721359549995794<br>
      </td>
    </tr>
    <tr>
      <td style="vertical-align: top;">eigvecs(A,
[eigvals,][permute=true,][scale=true]) <br>
Å® Matrix </td>
      <td style="vertical-align: top;">Returns a matrix M whose columns
are the
eigenvectors of A. (The kth eigenvector can be obtained from the slice
M[:, k].) The permute and scale keywords are the same as for eigfact().<br>
For SymTridiagonal matrices, if the optional vector
of eigenvalues eigvals is specified, returns the specific corresponding
eigenvectors.<br>
      </td>
      <td style="vertical-align: top;">eigvecs([2 4;4 6]) </td>
      <td style="vertical-align: top;">2x2 Array{Float64,2}:<br>
&nbsp;-0.850651&nbsp; 0.525731<br>
&nbsp; 0.525731&nbsp; 0.850651<br>
      <br>
      </td>
    </tr>
    <tr>
      <td style="vertical-align: top;">eigfact(A,[irange,][vl,][vu,][permute=true,][scale=true])
Å® Eigen </td>
      <td style="vertical-align: top;">Computes the eigenvalue
decomposition of A,
returning an Eigen factorization object F which contains the
eigenvalues in F[:values] and the eigenvectors in the columns of the
matrix F[:vectors]. (The kth eigenvector can be obtained from the slice
F[:vectors][:, k].)<br>
The following functions are available for Eigen
objects: inv, det.<br>
If A is Symmetric, Hermitian or SymTridiagonal, it
is possible to calculate only a subset of the eigenvalues by specifying
either a UnitRange irange covering indices of the sorted eigenvalues or
a pair vl and vu for the lower and upper boundaries of the eigenvalues.<br>
For general nonsymmetric matrices it is possible to
specify how the matrix is balanced before the eigenvector calculation.
The option permute=true permutes the matrix to become closer to upper
triangular, and scale=true scales the matrix by its diagonal elements
to make rows and columns more equal in norm. The default is true for
both options.<br>
      </td>
      <td style="vertical-align: top;">eigfact([2 4;4 6]) </td>
      <td style="vertical-align: top;">Base.LinAlg.Eigen{Float64,Float64,Array{Float64,2},Array{Float64,1}}([-0.4721359<br>
549995794,8.47213595499958],2x2 Array{Float64,2}:<br>
&nbsp;-0.850651&nbsp; 0.525731<br>
&nbsp; 0.525731&nbsp; 0.850651)<br>
      </td>
    </tr>
    <tr>
      <td style="vertical-align: top;">eigfact(A, B)<br>
&nbsp;Å® GeneralizedEigen </td>
      <td style="vertical-align: top;">Computes the generalized
eigenvalue decomposition of
A and B, returning a GeneralizedEigen factorization object F which
contains the generalized eigenvalues in F[:values] and the generalized
eigenvectors in the columns of the matrix F[:vectors]. (The kth
generalized eigenvector can be obtained from the slice F[:vectors][:,
k].)<br>
      </td>
      <td style="vertical-align: top;">eigfact([2 3;4 1], [5 4;4 3]) </td>
      <td style="vertical-align: top;">Base.LinAlg.GeneralizedEigen{Float64,Float64,Array{Float64,2},Array{Float64,1}}(<br>
[16.38986691902977,0.61013308097025],2x2 Array{Float64,2}:<br>
&nbsp; 0.782489&nbsp; 0.532489<br>
&nbsp;-1.0&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
1.0&nbsp;&nbsp;&nbsp;&nbsp; )<br>
      </td>
    </tr>
    <tr>
      <td style="vertical-align: top;">eigfact!(A[, B]) </td>
      <td style="vertical-align: top;">Same as eigfact(), but saves
space by overwriting
the input A (and B), instead of creating a copy.<br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
    </tr>
    <tr>
      <td style="vertical-align: top;">hessfact(A) </td>
      <td style="vertical-align: top;">Compute the Hessenberg
decomposition of A and return
a Hessenberg object. If F is the factorization object, the unitary
matrix can be accessed with F[:Q] and the Hessenberg matrix with F[:H].
When Q is extracted, the resulting type is the HessenbergQ object, and
may be converted to a regular matrix with full().<br>
      </td>
      <td style="vertical-align: top;">hessfact([2 3;4 1]) </td>
      <td style="vertical-align: top;">Base.LinAlg.Hessenberg{Float64,Array{Float64,2}}(2x2
Array{Float64,2}:<br>
&nbsp;2.0&nbsp; 3.0<br>
&nbsp;4.0&nbsp; 1.0,[0.0])<br>
      </td>
    </tr>
    <tr>
      <td style="vertical-align: top;">hessfact!(A) </td>
      <td style="vertical-align: top;">hessfact! is the same as
hessfact(), but saves space
by overwriting the input A, instead of creating a copy.<br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
    </tr>
    <tr>
      <td style="vertical-align: top;">schurfact(A) <br>
Å® Schur </td>
      <td style="vertical-align: top;">Computes the Schur factorization
of the matrix A.
The (quasi) triangular Schur factor can be obtained from the Schur
object F with either F[:Schur] or F[:T] and the unitary/orthogonal
Schur vectors can be obtained with F[:vectors] or F[:Z] such that
A=F[:vectors]*F[:Schur]*F[:vectors]'. The eigenvalues of A can be
obtained with F[:values].<br>
      </td>
      <td style="vertical-align: top;">schurfact([2 3;4 1]) </td>
      <td style="vertical-align: top;">Base.LinAlg.Schur{Float64,Array{Float64,2}}(2x2
Array{Float64,2}:<br>
&nbsp;5.0&nbsp; -1.0<br>
&nbsp;0.0&nbsp; -2.0,2x2 Array{Float64,2}:<br>
&nbsp;0.707107&nbsp; -0.707107<br>
&nbsp;0.707107&nbsp;&nbsp; 0.707107,[5.0,-2.0])<br>
      </td>
    </tr>
    <tr>
      <td style="vertical-align: top;">schurfact!(A) </td>
      <td style="vertical-align: top;">Computes the Schur factorization
of A, overwriting A
in the process. See schurfact()<br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
    </tr>
    <tr>
      <td style="vertical-align: top;">schur(A) <br>
Å® Schur[:T], Schur[:Z],
Schur[:values] </td>
      <td style="vertical-align: top;">See schurfact()<br>
      </td>
      <td style="vertical-align: top;">schur([1 2;4 5]) </td>
      <td style="vertical-align: top;">(<br>
2x2 Array{Float64,2}:<br>
&nbsp;-0.464102&nbsp; -2.0<br>
&nbsp; 0.0&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 6.4641,<br>
2x2 Array{Float64,2}:<br>
&nbsp;-0.806898&nbsp; -0.59069<br>
&nbsp; 0.59069&nbsp;&nbsp; -0.806898,<br>
[-0.4641016151377544,6.464101615137754])<br>
      </td>
    </tr>
    <tr>
      <td style="vertical-align: top;">ordschur(Q, T, select)<br>
&nbsp;Å® Schur </td>
      <td style="vertical-align: top;">Reorders the Schur factorization
of a real matrix
A=Q*T*Q' according to the logical array select returning a Schur object
F. The selected eigenvalues appear in the leading diagonal of F[:Schur]
and the the corresponding leading columns of F[:vectors] form an
orthonormal basis of the corresponding right invariant subspace. A
complex conjugate pair of eigenvalues must be either both included or
excluded via select.<br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
    </tr>
    <tr>
      <td style="vertical-align: top;">rdschur!(Q, T, select) Å® Schur </td>
      <td style="vertical-align: top;">Reorders the Schur factorization
of a real matrix
A=Q*T*Q', overwriting Q and T in the process. See ordschur()<br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
    </tr>
    <tr>
      <td style="vertical-align: top;">ordschur(S, select) Å® Schur </td>
      <td style="vertical-align: top;">Reorders the Schur factorization
S of type Schur.<br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
    </tr>
    <tr>
      <td style="vertical-align: top;">ordschur!(S, select) Å® Schur </td>
      <td style="vertical-align: top;">Reorders the Schur factorization
S of type Schur,
overwriting S in the process. See ordschur()<br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
    </tr>
    <tr>
      <td style="vertical-align: top;">schurfact(A, B) Å®
GeneralizedSchur </td>
      <td style="vertical-align: top;">Computes the Generalized Schur
(or QZ) factorization
of the matrices A and B. The (quasi) triangular Schur factors can be
obtained from the Schur object F with F[:S] and F[:T], the left
unitary/orthogonal Schur vectors can be obtained with F[:left] or F[:Q]
and the right unitary/orthogonal Schur vectors can be obtained with
F[:right] or F[:Z] such that A=F[:left]*F[:S]*F[:right]' and
B=F[:left]*F[:T]*F[:right]'. The generalized eigenvalues of A and B can
be obtained with F[:alpha]./F[:beta].<br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
    </tr>
    <tr>
      <td style="vertical-align: top;">schur(A, B) <br>
Å® GeneralizedSchur[:S], <br>
GeneralizedSchur[:T], <br>
GeneralizedSchur[:Q],<br>
GeneralizedSchur[:Z] </td>
      <td style="vertical-align: top;">See schurfact()<br>
      </td>
      <td style="vertical-align: top;">schur([2 4;4 1], [4 5;7 6]) </td>
      <td style="vertical-align: top;">(<br>
2x2 Array{Float64,2}:<br>
&nbsp;4.75224&nbsp; 2.39529<br>
&nbsp;0.0&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 2.94598,<br>
2x2 Array{Float64,2}:<br>
&nbsp;8.85937&nbsp; 6.78011<br>
&nbsp;0.0&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 1.24162,<br>
2x2 Array{Float64,2}:<br>
&nbsp;-0.510754&nbsp; -0.859727<br>
&nbsp;-0.859727&nbsp;&nbsp; 0.510754,<br>
2x2 Array{Float64,2}:<br>
&nbsp;-0.99395&nbsp;&nbsp;&nbsp; 0.109832<br>
&nbsp;-0.109832&nbsp; -0.99395 )<br>
      </td>
    </tr>
    <tr>
      <td style="vertical-align: top;">ordschur(S, T, Q, Z, select) <br>
Å®
GeneralizedSchur </td>
      <td style="vertical-align: top;">Reorders the Generalized Schur
factorization of a
matrix (A, B) = (Q*S*Z^{H}, Q*T*Z^{H}) according to the logical array
select and returns a GeneralizedSchur object GS. The selected
eigenvalues appear in the leading diagonal of both (GS[:S], GS[:T]) and
the left and right unitary/orthogonal Schur vectors are also reordered
such that (A, B) = GS[:Q]*(GS[:S], GS[:T])*GS[:Z]^{H} still holds and
the generalized eigenvalues of A and B can still be obtained with
GS[:alpha]./GS[:beta].<br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
    </tr>
    <tr>
      <td style="vertical-align: top;">ordschur!(S, T, Q, Z, select) <br>
Å®
GeneralizedSchur </td>
      <td style="vertical-align: top;">Reorders the Generalized Schur
factorization of a
matrix by overwriting the matrices (S, T, Q, Z) in the process. See
ordschur().<br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
    </tr>
    <tr>
      <td style="vertical-align: top;">ordschur(GS, select) <br>
Å®
GeneralizedSchur </td>
      <td style="vertical-align: top;">Reorders the Generalized Schur
factorization of a
Generalized Schur object. See ordschur().<br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
    </tr>
    <tr>
      <td style="vertical-align: top;">ordschur!(GS, select) <br>
Å®
GeneralizedSchur </td>
      <td style="vertical-align: top;">Reorders the Generalized Schur
factorization of a
Generalized Schur object by overwriting the object with the new
factorization. See ordschur().<br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
    </tr>
    <tr>
      <td style="vertical-align: top;">svdfact(A[, thin=true]) <br>
Å® SVD </td>
      <td style="vertical-align: top;">Compute the Singular Value
Decomposition (SVD) of A
and return an SVD object. U, S, V and Vt can be obtained from the
factorization F with F[:U], F[:S], F[:V] and F[:Vt], such that A =
U*diagm(S)*Vt. If thin is true, an economy mode decomposition is
returned. The algorithm produces Vt and hence Vt is more efficient to
extract than V. The default is to produce a thin decomposition.<br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
    </tr>
    <tr>
      <td style="vertical-align: top;">svdfact!(A[, thin=true]) <br>
Å® SVD </td>
      <td style="vertical-align: top;">svdfact! is the same as
svdfact(), but saves space
by overwriting the input A, instead of creating a copy. If thin is
true, an economy mode decomposition is returned. The default is to
produce a thin decomposition.<br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
    </tr>
    <tr>
      <td style="vertical-align: top;">svd(A[, thin=true]) <br>
Å® U, S, V </td>
      <td style="vertical-align: top;">Wrapper around svdfact
extracting all parts the
factorization to a tuple. Direct use of svdfact is therefore generally
more efficient. Computes the SVD of A, returning U, vector S, and V
such that A == U*diagm(S)*V'. If thin is true, an economy mode
decomposition is returned. The default is to produce a thin
decomposition.<br>
      </td>
      <td style="vertical-align: top;">svd([4 1]) </td>
      <td style="vertical-align: top;">(<br>
1x1 Array{Float64,2}:<br>
&nbsp;-1.0,<br>
[4.123105625617661],<br>
2x1 Array{Float64,2}:<br>
&nbsp;-0.970143<br>
&nbsp;-0.242536)<br>
      </td>
    </tr>
    <tr>
      <td style="vertical-align: top;">svdvals(A) </td>
      <td style="vertical-align: top;">Returns the singular values of A.<br>
      </td>
      <td style="vertical-align: top;">svdvals([1 4]) </td>
      <td style="vertical-align: top;">1-element Array{Float64,1}:<br>
&nbsp;4.12311<br>
      </td>
    </tr>
    <tr>
      <td style="vertical-align: top;">svdvals!(A) </td>
      <td style="vertical-align: top;"><span id="result_box"
 class="short_text" lang="ja"><span class="">ì¸óÕ</span><span>Ç</span><span>è„
èëÇ´Ç∑ÇÈÇ±Ç∆Ç≈</span><span>ÉXÉyÅ[ÉX</span><span>Ç</span><span>êﬂñÒÇµÇ»Ç™ÇÁ</span><span>ÅA</span><span>A</span><span>ÇÃ</span><span
 class="">ì¡àŸíl</span><span class="">Çï‘ÇµÇ‹Ç∑</span><span class="">ÅB</span></span>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
    </tr>
    <tr>
      <td style="vertical-align: top;">svdfact(A, B) <br>
Å® GeneralizedSVD </td>
      <td style="vertical-align: top;">Compute the generalized SVD of A
and B, returning a
GeneralizedSVD Factorization object F, such that A =
F[:U]*F[:D1]*F[:R0]*F[:Q]' and B = F[:V]*F[:D2]*F[:R0]*F[:Q]'.<br>
      </td>
      <td style="vertical-align: top;">svdfact([2 3],[4 8]) </td>
      <td style="vertical-align: top;">Base.LinAlg.GeneralizedSVD{Float64,Array{Float64,2}}(1x1
Array{Float64,2}:<br>
&nbsp;1.0,1x1 Array{Float64,2}:<br>
&nbsp;1.0,2x2 Array{Float64,2}:<br>
&nbsp;-0.894427&nbsp; -0.447214<br>
&nbsp; 0.447214&nbsp; -0.894427,[1.0,0.0],[0.0,1.0],1,1,2x2
Array{Float64,2}:<br>
&nbsp;-0.447214&nbsp; -3.57771<br>
&nbsp; 0.0&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; -8.94427)<br>
      </td>
    </tr>
    <tr>
      <td style="vertical-align: top;">svd(A, B) <br>
Å® U, V, Q, D1, D2, R0 </td>
      <td style="vertical-align: top;">Wrapper around svdfact
extracting all parts the
factorization to a tuple. Direct use of svdfact is therefore generally
more efficient. The function returns the generalized SVD of A and B,
returning U, V, Q, D1, D2, and R0 such that A = U*D1*R0*Q' and B =
V*D2*R0*Q'.<br>
      </td>
      <td style="vertical-align: top;">svd([2 3], [4 8]) </td>
      <td style="vertical-align: top;">(<br>
1x1 Array{Float64,2}:<br>
&nbsp;1.0,<br>
1x1 Array{Float64,2}:<br>
&nbsp;1.0,<br>
2x2 Array{Float64,2}:<br>
&nbsp;-0.894427&nbsp; -0.447214<br>
&nbsp; 0.447214&nbsp; -0.894427,<br>
1x2 Array{Float64,2}:<br>
&nbsp;1.0&nbsp; 0.0,<br>
1x2 Array{Float64,2}:<br>
&nbsp;0.0&nbsp; 1.0,<br>
2x2 Array{Float64,2}:<br>
&nbsp;-0.447214&nbsp; -3.57771<br>
&nbsp; 0.0&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; -8.94427)<br>
      </td>
    </tr>
    <tr>
      <td style="vertical-align: top;">svdvals(A, B) </td>
      <td style="vertical-align: top;">Return only the singular values
from the generalized
singular value decomposition of A and B.<br>
      </td>
      <td style="vertical-align: top;">svdvals([2 5],[3 1]) </td>
      <td style="vertical-align: top;">2-element Array{Float64,1}:<br>
&nbsp;Inf<br>
&nbsp;&nbsp; 0.0<br>
      </td>
    </tr>
    <tr>
      <td style="vertical-align: top;">givens{T}(::T, ::T, ::Integer,
::Integer) <br>
Å® {Givens, T} </td>
      <td style="vertical-align: top;">Computes the tuple (G, r) =
givens(f, g, i1, i2)
where G is a Givens rotation and r is a scalar such that G*x=y with
x[i1]=f, x[i2]=g, y[i1]=r, and y[i2]=0. The cosine and sine of the
rotation angle can be extracted from the Givens type with G.c and G.s
respectively. The arguments f and g can be either Float32, Float64,
Complex{Float32}, or Complex{Float64}. The Givens type supports left
multiplication G*A and conjugated transpose right multiplication A*G'.
The type doesnÅft have a size and can therefore be multiplied with
matrices of arbitrary size as long as i2&lt;=size(A,2) for G*A or
i2&lt;=size(A,1) for A*G'.<br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
    </tr>
    <tr>
      <td style="vertical-align: top;">givens{T}(::AbstractArray{T},
::Integer, ::Integer, ::Integer) <br>
Å®
{Givens, T} </td>
      <td style="vertical-align: top;">Computes the tuple (G, r) =
givens(A, i1, i2, col)
where G is Givens rotation and r is a scalar such that G*A[:,col]=y
with y[i1]=r, and y[i2]=0. The cosine and sine of the rotation angle
can be extracted from the Givens type with G.c and G.s respectively.
The element type of A can be either Float32, Float64, Complex{Float32},
or Complex{Float64}. The Givens type supports left multiplication G*A
and conjugated transpose right multiplication A*G'. The type doesnÅft
have a size and can therefore be multiplied with matrices of arbitrary
size as long as i2&lt;=size(A,2) for G*A or i2&lt;=size(A,1) for A*G'.<br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
    </tr>
    <tr>
      <td style="vertical-align: top;">triu(M) </td>
      <td style="vertical-align: top;">Upper triangle of a matrix.<br>
      </td>
      <td style="vertical-align: top;">triu([1 2;4 5]) </td>
      <td style="vertical-align: top;">2x2 Array{Int64,2}:<br>
&nbsp;1&nbsp; 2<br>
&nbsp;0&nbsp; 5<br>
      </td>
    </tr>
    <tr>
      <td style="vertical-align: top;">triu(M, k) </td>
      <td style="vertical-align: top;">Returns the upper triangle of M
starting from the
kth superdiagonal.<br>
      </td>
      <td style="vertical-align: top;">A=[1 2;4 5];<br>
triu(A, 1)<br>
      <br>
      <br>
      </td>
      <td style="vertical-align: top;">2x2 Array{Int64,2}:<br>
&nbsp;0&nbsp; 2<br>
&nbsp;0&nbsp; 0 </td>
    </tr>
    <tr>
      <td style="vertical-align: top;">triu!(M) </td>
      <td style="vertical-align: top;">Upper triangle of a matrix,
overwriting M in the
process.<br>
      </td>
      <td style="vertical-align: top;">A=[1 2;4 5]; triu!(A) </td>
      <td style="vertical-align: top;">2x2 Array{Int64,2}:<br>
&nbsp;1&nbsp; 2<br>
&nbsp;0&nbsp; 5<br>
      </td>
    </tr>
    <tr>
      <td style="vertical-align: top;">triu!(M, k) </td>
      <td style="vertical-align: top;">Returns the upper triangle of M
starting from the
kth superdiagonal, overwriting M in the process.<br>
MÇÃílÇ…åãâ Ç™ë„ì¸<br>
      </td>
      <td style="vertical-align: top;">A=[1 2;4 5];<br>
triu!(A, 2) </td>
      <td style="vertical-align: top;">2x2 Array{Int64,2}:<br>
&nbsp;0&nbsp; 0<br>
&nbsp;0&nbsp; 0<br>
      <br>
      </td>
    </tr>
    <tr>
      <td style="vertical-align: top;">tril(M) </td>
      <td style="vertical-align: top;">Lower triangle of a matrix.<br>
      </td>
      <td style="vertical-align: top;">A=[1 2;4 5];<br>
tril(A)<br>
      </td>
      <td style="vertical-align: top;">2x2 Array{Int64,2}:<br>
&nbsp;1&nbsp; 0<br>
&nbsp;4&nbsp; 5<br>
      </td>
    </tr>
    <tr>
      <td style="vertical-align: top;">tril(M, k) </td>
      <td style="vertical-align: top;">Returns the lower triangle of M
starting from the
kth superdiagonal.<br>
      </td>
      <td style="vertical-align: top;">A=[1 2;4 5];<br>
tril(A, 2) </td>
      <td style="vertical-align: top;">2x2 Array{Int64,2}:<br>
&nbsp;1&nbsp; 2<br>
&nbsp;4&nbsp; 5<br>
      </td>
    </tr>
    <tr>
      <td style="vertical-align: top;">tril!(M) </td>
      <td style="vertical-align: top;">Lower triangle of a matrix,
overwriting M in the
process.<br>
MÇÃílÇ…åãâ Ç™ë„ì¸<br>
      </td>
      <td style="vertical-align: top;">A=[1 2;4 5];<br>
tril!(A) </td>
      <td style="vertical-align: top;">2x2 Array{Int64,2}:<br>
&nbsp;1&nbsp; 0<br>
&nbsp;4&nbsp; 5<br>
      </td>
    </tr>
    <tr>
      <td style="vertical-align: top;">tril!(M, k) </td>
      <td style="vertical-align: top;">Returns the lower triangle of M
starting from the
kth superdiagonal, overwriting M in the process.<br>
      </td>
      <td style="vertical-align: top;">A=[1 2;4 5];<br>
tril!(A, 2) </td>
      <td style="vertical-align: top;">2x2 Array{Int64,2}:<br>
&nbsp;1&nbsp; 2<br>
&nbsp;4&nbsp; 5<br>
      </td>
    </tr>
    <tr>
      <td style="vertical-align: top;">diagind(M[, k]) </td>
      <td style="vertical-align: top;">A Range giving the indices of
the kth diagonal of
the matrix M.<br>
      </td>
      <td style="vertical-align: top;">A=[1 2;4 5];<br>
diagind(A) </td>
      <td style="vertical-align: top;">1:3:4<br>
      </td>
    </tr>
    <tr>
      <td style="vertical-align: top;">diag(M[, k]) </td>
      <td style="vertical-align: top;">The kth diagonal of a matrix, as
a vector. Use diagm
to construct a diagonal matrix.<br>
ëŒäpê¨ï™<br>
      </td>
      <td style="vertical-align: top;">A=[1 2;4 5];<br>
diag(A) </td>
      <td style="vertical-align: top;">2-element Array{Int64,1}:<br>
&nbsp;1<br>
&nbsp;5<br>
      </td>
    </tr>
    <tr>
      <td style="vertical-align: top;">diagm(v[, k]) </td>
      <td style="vertical-align: top;">Construct a diagonal matrix and
place v on the kth
diagonal.<br>
      </td>
      <td style="vertical-align: top;">diagm(vec([2 ,3]),1) </td>
      <td style="vertical-align: top;">3x3 Array{Int64,2}:<br>
&nbsp;0&nbsp; 2&nbsp; 0<br>
&nbsp;0&nbsp; 0&nbsp; 3<br>
&nbsp;0&nbsp; 0&nbsp; 0<br>
      </td>
    </tr>
    <tr>
      <td style="vertical-align: top;">scale(A, b)<br>
scale(b, A)</td>
      <td style="vertical-align: top;">çsóÒAÇÃê¨ï™Çbî{Ç∑ÇÈÅD<br>
      </td>
      <td style="vertical-align: top;">A=[1 2;4 5];<br>
scale(A, 2) </td>
      <td style="vertical-align: top;">2x2 Array{Int64,2}:<br>
&nbsp;2&nbsp;&nbsp; 4<br>
&nbsp;8&nbsp; 10<br>
      <br>
      </td>
    </tr>
    <tr>
      <td style="vertical-align: top;">scale!(A, b)<br>
scale!(b, A) </td>
      <td style="vertical-align: top;">Scale an array A by a scalar b,
similar to scale()
but overwriting A in-place.<br>
&nbsp;&nbsp;&nbsp; If A is a matrix and b is a vector, then scale!(A,b)
scales each column i of A by b[i] (similar to A*diagm(b)), while
scale!(b,A) scales each row i of A by b[i] (similar to diagm(b)*A),
again operating in-place on A.<br>
      </td>
      <td style="vertical-align: top;">A=[1 2;4 5];<br>
scale!(A, 2)<br>
      </td>
      <td style="vertical-align: top;">2x2 Array{Int64,2}:<br>
&nbsp;2&nbsp;&nbsp; 4<br>
&nbsp;8&nbsp; 10<br>
      </td>
    </tr>
    <tr>
      <td style="vertical-align: top;">Tridiagonal(dl, d, du) </td>
      <td style="vertical-align: top;">Construct a tridiagonal matrix
from the lower
diagonal, diagonal, and upper diagonal, respectively. The result is of
type Tridiagonal and provides efficient specialized linear solvers, but
may be converted into a regular matrix with full().<br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
    </tr>
    <tr>
      <td style="vertical-align: top;">Bidiagonal(dv, ev, isupper) </td>
      <td style="vertical-align: top;">Constructs an upper
(isupper=true) or lower
(isupper=false) bidiagonal matrix using the given diagonal (dv) and
off-diagonal (ev) vectors. The result is of type Bidiagonal and
provides efficient specialized linear solvers, but may be converted
into a regular matrix with full().<br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
    </tr>
    <tr>
      <td style="vertical-align: top;">SymTridiagonal(d, du) </td>
      <td style="vertical-align: top;">Construct a real symmetric
tridiagonal matrix from
the diagonal and upper diagonal, respectively. The result is of type
SymTridiagonal and provides efficient specialized eigensolvers, but may
be converted into a regular matrix with full().<br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
    </tr>
    <tr>
      <td style="vertical-align: top;">rank(M) </td>
      <td style="vertical-align: top;">Compute the rank of a matrix.<br>
çsóÒÇÃÉâÉìÉNÇãÅÇﬂÇÈì∆óßÇµÇƒÇ¢ÇÈäÓíÍ<br>
      </td>
      <td style="vertical-align: top;">rank([2 3 ;4 5])<br>
rank([2 3 ;4 6])<br>
      </td>
      <td style="vertical-align: top;">2<br>
1<br>
      </td>
    </tr>
    <tr>
      <td style="vertical-align: top;">norm(A[, p]) </td>
      <td style="vertical-align: top;">Compute the p-norm of a vector
or the operator norm
of a matrix A, defaulting to the p=2-norm.<br>
&nbsp;&nbsp;&nbsp; For vectors, p can assume any numeric value (even
though not all values produce a mathematically valid vector norm). In
particular, norm(A, Inf) returns the largest value in abs(A), whereas
norm(A, -Inf) returns the smallest.<br>
&nbsp;&nbsp;&nbsp; For matrices, the matrix norm induced by the vector
p-norm is used, where valid values of p are 1, 2, or Inf. (Note that
for sparse matrices, p=2 is currently not implemented.) Use vecnorm()
to compute the Frobenius norm.<br>
      </td>
      <td style="vertical-align: top;">A=[1 2;4 5];<br>
norm(A) </td>
      <td style="vertical-align: top;">6.7678289356323695<br>
      </td>
    </tr>
    <tr>
      <td style="vertical-align: top;">vecnorm(A[, p]) </td>
      <td style="vertical-align: top;">For any iterable container A
(including arrays of
any dimension) of numbers (or any element type for which norm is
defined), compute the p-norm (defaulting to p=2) as if A were a vector
of the corresponding length.<br>
&nbsp;&nbsp;&nbsp; For example, if A is a matrix and p=2, then this is
equivalent to the Frobenius norm.<br>
      </td>
      <td style="vertical-align: top;">A=[2 4;8 10];<br>
vecnorm(A) </td>
      <td style="vertical-align: top;">13.564659966250536<br>
      <br>
      </td>
    </tr>
    <tr>
      <td style="vertical-align: top;">cond(M[, p]) </td>
      <td style="vertical-align: top;">Condition number of the matrix
M, computed using the
operator p-norm. Valid values for p are 1, 2 (default), or Inf.<br>
      </td>
      <td style="vertical-align: top;">A=[1 2;4 5];<br>
cond(A) </td>
      <td style="vertical-align: top;">15.267836167327582<br>
      <br>
      </td>
    </tr>
    <tr>
      <td style="vertical-align: top;">condskeel(M[, x, p])</td>
      <td style="vertical-align: top;">É»S(M,p)É»S(M,x,p)=ÅaÅa|M|&#8739;&#8739;MÅ|1&#8739;&#8739;ÅaÅap=
ÅaÅa|M|&#8739;&#8739;MÅ|1&#8739;&#8739;|x|ÅaÅap<br>
É»S(M,p)=Åa|M||MÅ|1|ÅapÉ»S(M,x,p)=Åa|M||MÅ|1||x|Åap<br>
&nbsp;&nbsp;&nbsp; Skeel condition number É»SÉ»S of the matrix M,
optionally with respect to the vector x, as computed using the operator
p-norm. p is Inf by default, if not provided. Valid values for p are 1,
2, or Inf.<br>
&nbsp;&nbsp;&nbsp; This quantity is also known in the literature as the
Bauer condition number, relative condition number, or componentwise
relative condition number.</td>
      <td style="vertical-align: top;">A=[1 2;4 5];<br>
condskeel(A)<br>
      </td>
      <td style="vertical-align: top;">11.0<br>
      <br>
      </td>
    </tr>
    <tr>
      <td style="vertical-align: top;">trace(M) </td>
      <td style="vertical-align: top;">çsóÒÉgÉåÅ[ÉX </td>
      <td style="vertical-align: top;">trace([1 2;3 5]) </td>
      <td style="vertical-align: top;">6<br>
      <br>
      </td>
    </tr>
    <tr>
      <td style="vertical-align: top;">det(M) </td>
      <td style="vertical-align: top;">çsóÒílÅ@[a b;c d]= ad-bc<br>
      </td>
      <td style="vertical-align: top;"> det([2 3;4 5]) </td>
      <td style="vertical-align: top;">-2.0<br>
      </td>
    </tr>
    <tr>
      <td style="vertical-align: top;">logdet(M) </td>
      <td style="vertical-align: top;">Log of matrix determinant.
Equivalent to
log(det(M)), but may provide increased accuracy and/or speed.<br>
      </td>
      <td style="vertical-align: top;">logdet([2 3;4 9]) </td>
      <td style="vertical-align: top;">1.791759469228055<br>
      <br>
      </td>
    </tr>
    <tr>
      <td style="vertical-align: top;">logabsdet(M) </td>
      <td style="vertical-align: top;">Log of absolute value of
determinant of real matrix.
Equivalent to (log(abs(det(M))), sign(det(M))), but may provide
increased accuracy and/or speed.<br>
      </td>
      <td style="vertical-align: top;">&nbsp;logabsdet([2 3;5 3]) </td>
      <td style="vertical-align: top;">(2.1972245773362196,-1.0)<br>
      <br>
      </td>
    </tr>
    <tr>
      <td style="vertical-align: top;">inv(M) </td>
      <td style="vertical-align: top;">ãtçsóÒ<br>
      </td>
      <td style="vertical-align: top;">inv([2 3;5 3]) </td>
      <td style="vertical-align: top;">2x2 Array{Float64,2}:<br>
&nbsp;-0.333333&nbsp;&nbsp; 0.333333<br>
&nbsp; 0.555556&nbsp; -0.222222<br>
      </td>
    </tr>
    <tr>
      <td style="vertical-align: top;">pinv(M[, tol]) </td>
      <td style="vertical-align: top;">Computes the Moore-Penrose
pseudoinverse.<br>
&nbsp;&nbsp;&nbsp; For matrices M with floating point elements, it is
convenient to compute the pseudoinverse by inverting only singular
values above a given threshold, tol.<br>
&nbsp;&nbsp;&nbsp; The optimal choice of tol varies both with the value
of M and the intended application of the pseudoinverse. The default
value of tol is eps(real(float(one(eltype(M)))))*maximum(size(A)),
which is essentially machine epsilon for the real part of a matrix
element multiplied by the larger matrix dimension. For inverting dense
ill-conditioned matrices in a least-squares sense, tol =
sqrt(eps(real(float(one(eltype(M)))))) is recommended.<br>
&nbsp;&nbsp;&nbsp; For more information, see [issue8859], [B96], [S84],
[KY88].<br>
&nbsp;&nbsp;&nbsp; [issue8859] &nbsp;&nbsp;&nbsp; Issue 8859, ÅgFix
least squaresÅh, https://github.com/JuliaLang/julia/pull/8859<br>
&nbsp;&nbsp;&nbsp; [B96] &nbsp;&nbsp;&nbsp; &#197;ke Bj&#246;rck, ÅgNumerical
Methods for Least Squares ProblemsÅh, SIAM Press, Philadelphia, 1996,
ÅgOther Titles in Applied MathematicsÅh, Vol. 51.
doi:10.1137/1.9781611971484<br>
&nbsp;&nbsp;&nbsp; [S84] &nbsp;&nbsp;&nbsp; G. W. Stewart, ÅgRank
DegeneracyÅh, SIAM Journal on Scientific and Statistical Computing,
5(2), 1984, 403-413. doi:10.1137/0905030<br>
&nbsp;&nbsp;&nbsp; [KY88] &nbsp;&nbsp;&nbsp; Konstantinos
Konstantinides and Kung Yao, ÅgStatistical analysis of effective
singular values in matrix rank determinationÅh, IEEE Transactions on
Acoustics, Speech and Signal Processing, 36(5), 1988, 757-763.
doi:10.1109/29.1585<br>
      </td>
      <td style="vertical-align: top;">pinv([2 3;5 3],0) </td>
      <td style="vertical-align: top;">2x2 Array{Float64,2}:<br>
&nbsp;-0.333333&nbsp;&nbsp; 0.333333<br>
&nbsp; 0.555556&nbsp; -0.222222<br>
      </td>
    </tr>
    <tr>
      <td style="vertical-align: top;">nullspace(M) </td>
      <td style="vertical-align: top;">Basis for nullspace of M.<br>
      </td>
      <td style="vertical-align: top;">nullspace([2 3;4 2]) </td>
      <td style="vertical-align: top;">2x0 Array{Float64,2}<br>
      <br>
      </td>
    </tr>
    <tr>
      <td style="vertical-align: top;">repmat(A, n, m) </td>
      <td style="vertical-align: top;">Construct a matrix by repeating
the given matrix n
times in dimension 1 and m times in dimension 2.<br>
      </td>
      <td style="vertical-align: top;">A=[1 2;4 5];<br>
repmat(A, 2, 1)<br>
      </td>
      <td style="vertical-align: top;">4x2 Array{Int64,2}:<br>
&nbsp;1&nbsp; 2<br>
&nbsp;4&nbsp; 5<br>
&nbsp;1&nbsp; 2<br>
&nbsp;4&nbsp; 5<br>
      </td>
    </tr>
    <tr>
      <td style="vertical-align: top;">repeat(A, inner = Int[], outer =
Int[]) </td>
      <td style="vertical-align: top;">Construct an array by repeating
the entries of A.
The i-th element of inner specifies the number of times that the
individual entries of the i-th dimension of A should be repeated. The
i-th element of outer specifies the number of times that a slice along
the i-th dimension of A should be repeated.<br>
      </td>
      <td style="vertical-align: top;">A=[1 2;4 5];<br>
repeat(A)<br>
      </td>
      <td style="vertical-align: top;">2x2 Array{Int64,2}:<br>
&nbsp;1&nbsp; 2<br>
&nbsp;4&nbsp; 5<br>
      </td>
    </tr>
    <tr>
      <td style="vertical-align: top;">kron(A, B) </td>
      <td style="vertical-align: top;">Kronecker tensor product of two
vectors or two
matrices.<br>
      </td>
      <td style="vertical-align: top;">A=[1 2;4 5];<br>
B=[2 3;4 2];<br>
kron(A, B)<br>
      </td>
      <td style="vertical-align: top;">4x4 Array{Int64,2}:<br>
&nbsp; 2&nbsp;&nbsp; 3&nbsp;&nbsp; 4&nbsp;&nbsp; 6<br>
&nbsp; 4&nbsp;&nbsp; 2&nbsp;&nbsp; 8&nbsp;&nbsp; 4<br>
&nbsp; 8&nbsp; 12&nbsp; 10&nbsp; 15<br>
&nbsp;16&nbsp;&nbsp; 8&nbsp; 20&nbsp; 10<br>
      </td>
    </tr>
    <tr>
      <td style="vertical-align: top;">blkdiag(A...) </td>
      <td style="vertical-align: top;">Concatenate matrices
block-diagonally. Currently
only implemented for sparse matrices.<br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
    </tr>
    <tr>
      <td style="vertical-align: top;">linreg(x, y) <br>
Å® a, b </td>
      <td style="vertical-align: top;">Perform linear regression.
Returns a and b such that
a + b*x is the closest straight line to the given points (x, y), i.e.,
such that the squared error between y and a + b*x is minimized.<br>
      <br>
      <br>
      <br>
      <br>
      </td>
      <td style="vertical-align: top; width: 200px;">&nbsp;linreg([2],
[3])<br>
      <br>
&nbsp;&nbsp;
using PyPlot<br>
&nbsp;&nbsp;&nbsp; x = [1.0:12.0;]<br>
&nbsp;&nbsp;&nbsp; y = [5.5, 6.3, 7.6, 8.8, 10.9, 11.79, 13.48, 15.02,
17.77, 20.81, 22.0, 22.99]<br>
&nbsp;&nbsp;&nbsp; a, b = linreg(x,
y)&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; # Linear
regression<br>
&nbsp;&nbsp;&nbsp; plot(x, y,
"o")&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
# Plot (x, y) points<br>
&nbsp;&nbsp;&nbsp; plot(x, [a+b*i for i in x])&nbsp; # Plot line
determined by linear regression&nbsp;</td>
      <td style="vertical-align: top;">2-element Array{Float64,1}:<br>
&nbsp;0.6<br>
&nbsp;1.2<br>
      <br>
      </td>
    </tr>
    <tr>
      <td style="vertical-align: top;">linreg(x, y, w) </td>
      <td style="vertical-align: top;">Weighted least-squares linear
regression.<br>
      </td>
      <td style="vertical-align: top;">linreg([2], [3], [5]) </td>
      <td style="vertical-align: top;">2-element Array{Float64,1}:<br>
&nbsp;0.6<br>
&nbsp;1.2<br>
      <br>
      </td>
    </tr>
    <tr>
      <td style="vertical-align: top;">expm(A) </td>
      <td style="vertical-align: top;">Compute the matrix exponential
of A, defined by<br>
&nbsp;&nbsp;&nbsp; eA=áîn=0ÅáAnn!.<br>
&nbsp;&nbsp;&nbsp; eA=áîn=0ÅáAnn!.<br>
&nbsp;&nbsp;&nbsp; For symmetric or Hermitian A, an eigendecomposition
(eigfact()) is used, otherwise the scaling and squaring algorithm (see
[H05]) is chosen.<br>
&nbsp;&nbsp;&nbsp; [H05] &nbsp;&nbsp;&nbsp; Nicholas J. Higham, ÅgThe
squaring and scaling method for the matrix exponential revisitedÅh, SIAM
Journal on Matrix Analysis and Applications, 26(4), 2005, 1179-1193.
doi:10.1137/090768539<br>
      </td>
      <td style="vertical-align: top;">exp([2 3;4 2]) </td>
      <td style="vertical-align: top;">2x2 Array{Float64,2}:<br>
&nbsp; 7.38906&nbsp; 20.0855<br>
&nbsp;54.5982&nbsp;&nbsp;&nbsp; 7.38906<br>
      </td>
    </tr>
    <tr>
      <td style="vertical-align: top;">logm(A) </td>
      <td style="vertical-align: top;">If A has no negative real
eigenvalue, compute the
principal matrix logarithm of A, i.e. the unique matrix XX such that
eX=AeX=A and Å|ÉŒ&lt;Im(É…)&lt;ÉŒÅ|ÉŒ&lt;Im(É…)&lt;ÉŒ for all the eigenvalues
É…É… of XX. If A has nonpositive eigenvalues, a warning is printed and
whenever possible a nonprincipal matrix function is returned.<br>
&nbsp;&nbsp;&nbsp; If A is symmetric or Hermitian, its
eigendecomposition (eigfact()) is used, if A is triangular an improved
version of the inverse scaling and squaring method is employed (see
[AH12] and [AHR13]). For general matrices, the complex Schur form
(schur()) is computed and the triangular algorithm is used on the
triangular factor.<br>
&nbsp;&nbsp;&nbsp; [AH12] &nbsp;&nbsp;&nbsp; Awad H. Al-Mohy and
Nicholas J. Higham, ÅgImproved inverse scaling and squaring algorithms
for the matrix logarithmÅh, SIAM Journal on Scientific Computing, 34(4),
2012, C153-C169. doi:10.1137/110852553<br>
&nbsp;&nbsp;&nbsp; [AHR13] &nbsp;&nbsp;&nbsp; Awad H. Al-Mohy, Nicholas
J. Higham and Samuel D. Relton, ÅgComputing the Fr&#233;chet derivative of
the matrix logarithm and estimating the condition numberÅh, SIAM Journal
on Scientific Computing, 35(4), 2013, C394-C410. doi:10.1137/120885991 </td>
      <td style="vertical-align: top;">A=[3 1;-2 5];<br>
logm(A) </td>
      <td style="vertical-align: top;">2x2 Array{Float64,2}:<br>
&nbsp; 1.17163&nbsp;&nbsp; 0.244979<br>
&nbsp;-0.489957&nbsp; 1.66159<br>
      </td>
    </tr>
    <tr>
      <td style="vertical-align: top;">sqrtm(A) </td>
      <td style="vertical-align: top;">&nbsp;&nbsp;&nbsp; If A has no
negative real eigenvalues, compute the
principal matrix square root of A, that is the unique matrix XX with
eigenvalues having positive real part such that X2=AX2=A. Otherwise, a
nonprincipal square root is returned.<br>
&nbsp;&nbsp;&nbsp; If A is symmetric or Hermitian, its
eigendecomposition (eigfact()) is used to compute the square root.
Otherwise, the square root is determined by means of the
Bj&#246;rck-Hammarling method, which computes the complex Schur form
(schur()) and then the complex square root of the triangular factor.<br>
&nbsp;&nbsp;&nbsp; [BH83] &nbsp;&nbsp;&nbsp; &#197;ke Bj&#246;rck and Sven
Hammarling, ÅgA Schur method for the square root of a matrixÅh, Linear
Algebra and its Applications, 52-53, 1983, 127-140.
doi:10.1016/0024-3795(83)80010-X<br>
      </td>
      <td style="vertical-align: top;">A=[3 1;-2 5]; sqrtm(A) </td>
      <td style="vertical-align: top;">2x2 Array{Complex{Float64},2}:<br>
&nbsp;&nbsp; 1.76723-1.66533e-16im&nbsp; 0.248098+1.11022e-16im<br>
&nbsp;-0.496197-3.33067e-16im&nbsp;&nbsp; 2.26343-8.32667e-17im<br>
      <br>
      </td>
    </tr>
    <tr>
      <td style="vertical-align: top;">lyap(A, C) </td>
      <td style="vertical-align: top;">&nbsp;&nbsp;&nbsp; Computes the
solution X to the continuous Lyapunov
equation AX + XA' + C = 0, where no eigenvalue of A has a zero real
part and no two eigenvalues are negative complex conjugates of each
other.<br>
      </td>
      <td style="vertical-align: top;">A=[3 1;-2 5];<br>
C=[1 2;3 1];<br>
lyap(A, C)<br>
      </td>
      <td style="vertical-align: top;">2x2 Array{Float64,2}:<br>
&nbsp;-0.0661765&nbsp; -0.238971<br>
&nbsp;-0.363971&nbsp;&nbsp; -0.220588<br>
      </td>
    </tr>
    <tr>
      <td style="vertical-align: top;">sylvester(A, B, C) </td>
      <td style="vertical-align: top;">Computes the solution X to the
Sylvester equation AX
+ XB + C = 0, where A, B and C have compatible dimensions and A and -B
have no eigenvalues with equal real part.<br>
      </td>
      <td style="vertical-align: top;">A=[3 1;-2 5];<br>
B=[1 4;2 6];<br>
C=[1 2;3 1];<br>
sylvester(A, B, C)<br>
      </td>
      <td style="vertical-align: top;">sylvester(A, B, C)<br>
2x2 Array{Float64,2}:<br>
&nbsp;-0.00682057&nbsp; -0.225603<br>
&nbsp;-0.521511&nbsp;&nbsp;&nbsp;&nbsp; 0.0577125<br>
      </td>
    </tr>
    <tr>
      <td style="vertical-align: top;">issym(A) Å® Bool </td>
      <td style="vertical-align: top;">Test whether a matrix is
symmetric.<br>
      </td>
      <td style="vertical-align: top;">A=[3 1;-2 5];<br>
issym(A)<br>
      </td>
      <td style="vertical-align: top;">false </td>
    </tr>
    <tr>
      <td style="vertical-align: top;">isposdef(A) Å® Bool </td>
      <td style="vertical-align: top;">Test whether a matrix is
positive definite.<br>
      </td>
      <td style="vertical-align: top;">A=[3 1;-2 5];<br>
isposdef(A)<br>
      </td>
      <td style="vertical-align: top;">false<br>
      </td>
    </tr>
    <tr>
      <td style="vertical-align: top;">isposdef!(A) Å® Bool </td>
      <td style="vertical-align: top;">Test whether a matrix is
positive definite,
overwriting A in the processes.<br>
      </td>
      <td style="vertical-align: top;">A=[3 1;-2 5];<br>
isposdef!(A)<br>
      </td>
      <td style="vertical-align: top;">false<br>
      </td>
    </tr>
    <tr>
      <td style="vertical-align: top;">istril(A) Å® Bool </td>
      <td style="vertical-align: top;">Test whether a matrix is lower
triangular.<br>
      </td>
      <td style="vertical-align: top;">A=[3 1;-2 5];<br>
istril(A)<br>
      </td>
      <td style="vertical-align: top;">false<br>
      </td>
    </tr>
    <tr>
      <td style="vertical-align: top;">istriu(A) Å® Bool </td>
      <td style="vertical-align: top;">Test whether a matrix is upper
triangular.<br>
      </td>
      <td style="vertical-align: top;">A=[3 1;-2 5];<br>
istriu(A)<br>
      </td>
      <td style="vertical-align: top;">false<br>
      </td>
    </tr>
    <tr>
      <td style="vertical-align: top;">isdiag(A) Å® Bool </td>
      <td style="vertical-align: top;">Test whether a matrix is
diagonal.<br>
      </td>
      <td style="vertical-align: top;">A=[3 1;-2 5];<br>
isdiag(A)<br>
      </td>
      <td style="vertical-align: top;">false<br>
      </td>
    </tr>
    <tr>
      <td style="vertical-align: top;">ishermitian(A) Å® Bool </td>
      <td style="vertical-align: top;">Test whether a matrix is
Hermitian.<br>
      </td>
      <td style="vertical-align: top;">A=[3 1;-2 5];<br>
ishermitian(A)<br>
      </td>
      <td style="vertical-align: top;">false<br>
      </td>
    </tr>
    <tr>
      <td style="vertical-align: top;">transpose(A) </td>
      <td style="vertical-align: top;">The transposition operator (.').<br>
ì]íuçsóÒ<br>
      </td>
      <td style="vertical-align: top;">A=[3 1;-2 5];<br>
transpose(A)<br>
      </td>
      <td style="vertical-align: top;">2x2 Array{Int64,2}:<br>
&nbsp;3&nbsp; -2<br>
&nbsp;1&nbsp;&nbsp; 5<br>
      <br>
      </td>
    </tr>
    <tr>
      <td style="vertical-align: top;">transpose!(dest, src) </td>
      <td style="vertical-align: top;">Transpose array src and store
the result in the
preallocated array dest, which should have a size corresponding to
(size(src,2),size(src,1)). No in-place transposition is supported and
unexpected results will happen if src and dest have overlapping memory
regions.<br>
      </td>
      <td style="vertical-align: top;">transpose!([2,3,4],[2 4 5]) </td>
      <td style="vertical-align: top;">3-element Array{Int64,1}:<br>
&nbsp;2<br>
&nbsp;4<br>
&nbsp;5<br>
      </td>
    </tr>
    <tr>
      <td style="vertical-align: top;">ctranspose(A) </td>
      <td style="vertical-align: top;">The conjugate transposition
operator (').<br>
      </td>
      <td style="vertical-align: top;">A=[3 1;-2 5];<br>
ctranspose(A) </td>
      <td style="vertical-align: top;">2x2 Array{Int64,2}:<br>
&nbsp;3&nbsp; -2<br>
&nbsp;1&nbsp;&nbsp; 5<br>
      </td>
    </tr>
    <tr>
      <td style="vertical-align: top;">ctranspose!(dest, src) </td>
      <td style="vertical-align: top;">Conjugate transpose array src
and store the result
in the preallocated array dest, which should have a size corresponding
to (size(src,2),size(src,1)). No in-place transposition is supported
and unexpected results will happen if src and dest have overlapping
memory regions.<br>
      </td>
      <td style="vertical-align: top;">ctranspose!([2,3],[2 3])<br>
      <br>
      </td>
      <td style="vertical-align: top;">Ç»Ç…Ç‡ÇµÇ»Ç¢<br>
      </td>
    </tr>
    <tr>
      <td style="vertical-align: top;">eigs(A; nev=6, ncv=max(20,
2*nev+1), which="LM", tol=0.0, maxiter=300, sigma=nothing,
ritzvec=true, v0=zeros((0, ))) -&gt; (d, [v, ]nconv, niter, nmult,
resid) </td>
      <td style="vertical-align: top;">Computes eigenvalues d of A
using Lanczos or Arnoldi
iterations for real symmetric or general nonsymmetric matrices
respectively.<br>
&nbsp;&nbsp;&nbsp; The following keyword arguments are supported:<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; nev: Number of eigenvalues<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; ncv: Number of Krylov
vectors used in the computation; should satisfy nev+1 &lt;= ncv &lt;= n
for real symmetric problems and nev+2 &lt;= ncv &lt;= n for other
problems, where n is the size of the input matrix A. The default is ncv
= max(20,2*nev+1). Note that these restrictions limit the input matrix
A to be of dimension at least 2.<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; which: type of eigenvalues
to compute. See the note below.<br>
      <table cellpadding="2" cellspacing="2" border="1"
 style="text-align: left; width: 80%; margin-left: auto; margin-right: auto;">
        <tbody>
          <tr>
            <td style="vertical-align: top; font-weight: bold;">which </td>
            <td style="vertical-align: top; font-weight: bold;">type of
eigenvalues</td>
          </tr>
          <tr>
            <td style="vertical-align: top;">:LM </td>
            <td style="vertical-align: top;">eigenvalues of largest
magnitude (default)</td>
          </tr>
          <tr>
            <td style="vertical-align: top;">:SM </td>
            <td style="vertical-align: top;">eigenvalues of smallest
magnitude</td>
          </tr>
          <tr>
            <td style="vertical-align: top;">:LR</td>
            <td style="vertical-align: top;">eigenvalues of largest
real part</td>
          </tr>
          <tr>
            <td style="vertical-align: top;">:SR</td>
            <td style="vertical-align: top;">eigenvalues of smallest
real part</td>
          </tr>
          <tr>
            <td style="vertical-align: top;">:LI </td>
            <td style="vertical-align: top;">eigenvalues of largest
imaginary part (nonsymmetric or complex A only)</td>
          </tr>
          <tr>
            <td style="vertical-align: top;">:SI </td>
            <td style="vertical-align: top;">eigenvalues of smallest
imaginary part (nonsymmetric or complex A only)</td>
          </tr>
          <tr>
            <td style="vertical-align: top;">:BE</td>
            <td style="vertical-align: top;"> compute half of the
eigenvalues from each end of the spectrum, biased in favor of the high
end. (real symmetric A only)</td>
          </tr>
        </tbody>
      </table>
      <br>
&nbsp;&nbsp;&nbsp; tol: tolerance (tol&#8804;0.0tol&#8804;0.0 defaults to
DLAMCH('EPS'))<br>
&nbsp;&nbsp;&nbsp; maxiter: Maximum number of iterations (default = 300)<br>
&nbsp;&nbsp;&nbsp; sigma: Specifies the level shift used in inverse
iteration. If nothing (default), defaults to ordinary (forward)
iterations. Otherwise, find eigenvalues close to sigma using shift and
invert iterations.<br>
&nbsp;&nbsp;&nbsp; ritzvec: Returns the Ritz vectors v (eigenvectors)
if true<br>
&nbsp;&nbsp;&nbsp; v0: starting vector from which to start the
iterations<br>
eigs returns the nev requested eigenvalues in d, the corresponding Ritz
vectors v (only if ritzvec=true), the number of converged eigenvalues
nconv, the number of iterations niter and the number of matrix vector
multiplications nmult, as well as the final residual vector resid.<br>
Note<br>
The sigma and which keywords interact: the description of eigenvalues
searched for by which do _not_ necessarily refer to the eigenvalues of
A, but rather the linear operator constructed by the specification of
the iteration mode implied by sigma.<br>
&nbsp;&nbsp; <br>
      <table cellpadding="2" cellspacing="2" border="1"
 style="text-align: left; width: 80%; margin-left: auto; margin-right: auto;">
        <tbody>
          <tr>
            <td style="vertical-align: top; font-weight: bold;">sigma</td>
            <td style="vertical-align: top; font-weight: bold;">iteration
mode </td>
            <td style="vertical-align: top; font-weight: bold;">which
refers to eigenvalues of</td>
          </tr>
          <tr>
            <td style="vertical-align: top;">nothing &nbsp; <br>
            </td>
            <td style="vertical-align: top;">ordinary (forward)&nbsp; <br>
            </td>
            <td style="vertical-align: top;">AA</td>
          </tr>
          <tr>
            <td style="vertical-align: top;">real or complex </td>
            <td style="vertical-align: top;">inverse with level shift
sigma </td>
            <td style="vertical-align: top;"> (AÅ|É–I)^{Å|1}</td>
          </tr>
        </tbody>
      </table>
&nbsp;<br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
    </tr>
    <tr>
      <td style="vertical-align: top;">eigs(A, B; nev=6, ncv=max(20,
2*nev+1), which="LM", tol=0.0, maxiter=300, sigma=nothing,
ritzvec=true, v0=zeros((0, ))) -&gt; (d, [v, ]nconv, niter, nmult,
resid) </td>
      <td style="vertical-align: top;">Computes generalized eigenvalues
d of A and B using
Lanczos or Arnoldi iterations for real symmetric or general
nonsymmetric matrices respectively.<br>
&nbsp;&nbsp;&nbsp; The following keyword arguments are supported:<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; nev: Number of eigenvalues<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; ncv: Number of Krylov
vectors used in the computation; should satisfy nev+1 &lt;= ncv &lt;= n
for real symmetric problems and nev+2 &lt;= ncv &lt;= n for other
problems, where n is the size of the input matrices A and B. The
default is ncv = max(20,2*nev+1). Note that these restrictions limit
the input matrix A to be of dimension at least 2.<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; which: type of eigenvalues
to compute. See the note below.<br>
      <br>
      <table cellpadding="2" cellspacing="2" border="1"
 style="text-align: left; width: 80%; margin-left: auto; margin-right: auto;">
        <tbody>
          <tr>
            <td style="vertical-align: top; font-weight: bold;">which</td>
            <td style="vertical-align: top; font-weight: bold;">type of
eigenvalues</td>
          </tr>
          <tr>
            <td style="vertical-align: top;">:LM </td>
            <td style="vertical-align: top;">eigenvalues of largest
magnitude (default)</td>
          </tr>
          <tr>
            <td style="vertical-align: top;">:SM </td>
            <td style="vertical-align: top;">eigenvalues of smallest
magnitude</td>
          </tr>
          <tr>
            <td style="vertical-align: top;">:LR </td>
            <td style="vertical-align: top;">eigenvalues of largest
real part</td>
          </tr>
          <tr>
            <td style="vertical-align: top;">:SR </td>
            <td style="vertical-align: top;">eigenvalues of smallest
real part</td>
          </tr>
          <tr>
            <td style="vertical-align: top;">:LI&nbsp; <br>
            </td>
            <td style="vertical-align: top;">eigenvalues of largest
imaginary part (nonsymmetric or complex A only)</td>
          </tr>
          <tr>
            <td style="vertical-align: top;">:SI </td>
            <td style="vertical-align: top;">eigenvalues of smallest
imaginary part (nonsymmetric or complex A only)</td>
          </tr>
          <tr>
            <td style="vertical-align: top;">:BE</td>
            <td style="vertical-align: top;">compute half of the
eigenvalues from each end of the spectrum, biased in favor of the high
end. (real symmetric A only)</td>
          </tr>
        </tbody>
      </table>
      <br>
&nbsp;&nbsp;&nbsp; tol: tolerance (tol&#8804;0.0tol&#8804;0.0 defaults to
DLAMCH('EPS'))<br>
&nbsp;&nbsp;&nbsp; maxiter: Maximum number of iterations (default = 300)<br>
&nbsp;&nbsp;&nbsp; sigma: Specifies the level shift used in inverse
iteration. If nothing (default), defaults to ordinary (forward)
iterations. Otherwise, find eigenvalues close to sigma using shift and
invert iterations.<br>
&nbsp;&nbsp;&nbsp; ritzvec: Returns the Ritz vectors v (eigenvectors)
if true<br>
&nbsp;&nbsp;&nbsp; v0: starting vector from which to start the
iterations<br>
eigs returns the nev requested eigenvalues in d, the corresponding Ritz
vectors v (only if ritzvec=true), the number of converged eigenvalues
nconv, the number of iterations niter and the number of matrix vector
multiplications nmult, as well as the final residual vector resid.<br>
Note<br>
The sigma and which keywords interact: the description of eigenvalues
searched for by which do _not_ necessarily refer to the eigenvalue
problem Av=BvÉ…Av=BvÉ…, but rather the linear operator constructed by the
specification of the iteration mode implied by sigma.<br>
      <table cellpadding="2" cellspacing="2" border="1"
 style="text-align: left; width: 80%;">
        <tbody>
          <tr>
            <td style="vertical-align: top; font-weight: bold;">sigma</td>
            <td style="vertical-align: top; font-weight: bold;">iteration
mode&nbsp; <br>
            </td>
            <td style="vertical-align: top; font-weight: bold;">which
refers to the problem</td>
          </tr>
          <tr>
            <td style="vertical-align: top;">nothing</td>
            <td style="vertical-align: top;">ordinary (forward) </td>
            <td style="vertical-align: top;"> Av=BvÉ…Av=BvÉ…</td>
          </tr>
          <tr>
            <td style="vertical-align: top;">real or complex </td>
            <td style="vertical-align: top;"> inverse with level shift
sigma &nbsp; <br>
            </td>
            <td style="vertical-align: top;"> (AÅ|É–B)^{Å|1}B=vÉÀ</td>
          </tr>
        </tbody>
      </table>
&nbsp; <br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
    </tr>
    <tr>
      <td style="vertical-align: top;">
      <dl class="function">
        <dt id="Base.svds"><code class="descname"><span
 style="font-family: sans-serif;">svds(A; nsv=6, ritzvec=true, tol=0.0,
maxiter=1000)<br>
Å® (left_sv, s, right_sv, nconv, niter, nmult, resid)</span></code><span
 class="sig-paren"></span></dt>
      </dl>
      </td>
      <td style="vertical-align: top;">svds computes largest singular
values s of A using Lanczos or Arnoldi iterations. Uses eigs()
underneath.<br>
Inputs are:<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; * A: Linear operator. It can
either subtype of AbstractArray (e.g., sparse matrix) or duck typed.
For duck typing A has to support size(A), eltype(A), A * vector and A'
* vector.<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; * nsv: Number of singular
values.<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; * ritzvec: Whether to return
the left and right singular vectors left_sv and right_sv, default is
true. If false the singular vectors are omitted from the output.<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; * tol: tolerance, see eigs().<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; * maxiter: Maximum number of
iterations, see eigs(<br>
      </td>
      <td style="vertical-align: top;">X = sprand(10, 5, 0.2) </td>
      <td style="vertical-align: top;">10x5 sparse matrix with 15
Float64 entries:<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; [4 ,&nbsp; 1]&nbsp; =&nbsp;
0.241914<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; [8 ,&nbsp; 1]&nbsp; =&nbsp;
0.366137<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; [10,&nbsp; 1]&nbsp; =&nbsp;
0.728955<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; [1 ,&nbsp; 2]&nbsp; =&nbsp;
0.0256942<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; [5 ,&nbsp; 2]&nbsp; =&nbsp;
0.428058<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; [6 ,&nbsp; 2]&nbsp; =&nbsp;
0.099059<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; [7 ,&nbsp; 2]&nbsp; =&nbsp;
0.188451<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; [9 ,&nbsp; 2]&nbsp; =&nbsp;
0.217895<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; [10,&nbsp; 3]&nbsp; =&nbsp;
0.431959<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; [2 ,&nbsp; 4]&nbsp; =&nbsp;
0.200776<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; [1 ,&nbsp; 5]&nbsp; =&nbsp;
0.501743<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; [2 ,&nbsp; 5]&nbsp; =&nbsp;
0.649381<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; [3 ,&nbsp; 5]&nbsp; =&nbsp;
0.889147<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; [4 ,&nbsp; 5]&nbsp; =&nbsp;
0.590528<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; [7 ,&nbsp; 5]&nbsp; =&nbsp;
0.972049<br>
      </td>
    </tr>
    <tr>
      <td style="vertical-align: top;">peakflops(n; parallel=false)</td>
      <td style="vertical-align: top;">peakflops computes the peak flop
rate of the computer by using double precision
Base.LinAlg.BLAS.gemm!(). By default, if no arguments are specified, it
multiplies a matrix of size n x n, where n = 2000. If the underlying
BLAS is using multiple threads, higher flop rates are realized. The
number of BLAS threads can be set with blas_set_num_threads(n).<br>
If the keyword argument parallel is set to true, peakflops is run in
parallel on all the worker processors. The flop rate of the entire
parallel computer is returned. When running in parallel, only 1 BLAS
thread is used. The argument n still refers to the size of the problem
that is solved on each processor.<br>
      </td>
      <td style="vertical-align: top;">peakflops(5) </td>
      <td style="vertical-align: top;">4.230118443316413e7<br>
      </td>
    </tr>
  </tbody>
</table>
<br>
<br>
<br>
<table cellpadding="2" cellspacing="2" border="1"
 style="text-align: left; width: 100%;">
  <tbody>
    <tr>
      <td style="vertical-align: top;" rowspan="1" colspan="4"><span
 style="font-weight: bold;">BLAS Functions</span><br>
Base.LinAlg.BLAS provides wrappers for some of the BLAS functions for
linear algebra. Those BLAS functions that overwrite one of the input
arrays have names ending in '!'.<br>
Usually a function has 4 methods defined, one each for Float64,
Float32, Complex128 and Complex64 arrays.<br>
      </td>
    </tr>
    <tr>
      <td style="vertical-align: top; font-weight: bold;">èëéÆ<br>
      </td>
      <td style="vertical-align: top; font-weight: bold;">ã@î\<br>
      </td>
      <td style="vertical-align: top; font-weight: bold;">ó·ëË<br>
      </td>
      <td style="vertical-align: top; font-weight: bold;">åãâ <br>
      </td>
    </tr>
    <tr>
      <td style="vertical-align: top;">dot(n, X, incx, Y, incy) </td>
      <td style="vertical-align: top;">Dot product of two vectors
consisting of n elements
of array X with stride incx and n elements of array Y with stride incy.<br>
      </td>
      <td style="vertical-align: top;">&nbsp;&nbsp;&nbsp;&nbsp; <br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
    </tr>
    <tr>
      <td style="vertical-align: top;">dotu(n, X, incx, Y, incy) </td>
      <td style="vertical-align: top;">Dot function for two complex
vectors.<br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
    </tr>
    <tr>
      <td style="vertical-align: top;">dotc(n, X, incx, U, incy) </td>
      <td style="vertical-align: top;">Dot function for two complex
vectors conjugating the
first vector.<br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
    </tr>
    <tr>
      <td style="vertical-align: top;">blascopy!(n, X, incx, Y, incy) </td>
      <td style="vertical-align: top;">Copy n elements of array X with
stride incx to array
Y with stride incy. Returns Y.<br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
    </tr>
    <tr>
      <td style="vertical-align: top;">nrm2(n, X, incx) </td>
      <td style="vertical-align: top;">2-norm of a vector consisting of
n elements of array
X with stride incx.<br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
    </tr>
    <tr>
      <td style="vertical-align: top;">asum(n, X, incx) </td>
      <td style="vertical-align: top;">sum of the absolute values of
the first n elements
of array X with stride incx.<br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
    </tr>
    <tr>
      <td style="vertical-align: top;">axpy!(a, X, Y) </td>
      <td style="vertical-align: top;">Overwrite Y with a*X + Y.
Returns Y.<br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
    </tr>
    <tr>
      <td style="vertical-align: top;">scal!(n, a, X, incx) </td>
      <td style="vertical-align: top;">Overwrite X with a*X. Returns X.<br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
    </tr>
    <tr>
      <td style="vertical-align: top;">scal(n, a, X, incx) </td>
      <td style="vertical-align: top;">Returns a*X.<br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
    </tr>
    <tr>
      <td style="vertical-align: top;">ger!(alpha, x, y, A) </td>
      <td style="vertical-align: top;">Rank-1 update of the matrix A
with vectors x and y
as alpha*x*y' + A.<br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
    </tr>
    <tr>
      <td style="vertical-align: top;">syr!(uplo, alpha, x, A) </td>
      <td style="vertical-align: top;">Rank-1 update of the symmetric
matrix A with vector
x as alpha*x*x.' + A. When uplo is ÅeUÅf the upper triangle of A is
updated (ÅeLÅf for lower triangle). Returns A.<br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
    </tr>
    <tr>
      <td style="vertical-align: top;">syrk!(uplo, trans, alpha, A,
beta, C) </td>
      <td style="vertical-align: top;">Rank-k update of the symmetric
matrix C as
alpha*A*A.' + beta*C or alpha*A.'*A + beta*C according to whether trans
is ÅeNÅf or ÅeTÅf. When uplo is ÅeUÅf the upper triangle of C is updated (ÅeLÅf
for lower triangle). Returns C.<br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
    </tr>
    <tr>
      <td style="vertical-align: top;">syrk(uplo, trans, alpha, A) </td>
      <td style="vertical-align: top;">Returns either the upper
triangle or the lower
triangle, according to uplo (ÅeUÅf or ÅeLÅf), of alpha*A*A.' or
alpha*A.'*A, according to trans (ÅeNÅf or ÅeTÅf).<br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
    </tr>
    <tr>
      <td style="vertical-align: top;">her!(uplo, alpha, x, A) </td>
      <td style="vertical-align: top;">Methods for complex arrays only.
Rank-1 update of
the Hermitian matrix A with vector x as alpha*x*x' + A. When uplo is
ÅeUÅf the upper triangle of A is updated (ÅeLÅf for lower triangle).
Returns A.<br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
    </tr>
    <tr>
      <td style="vertical-align: top;">herk!(uplo, trans, alpha, A,
beta, C) </td>
      <td style="vertical-align: top;">Methods for complex arrays only.
Rank-k update of
the Hermitian matrix C as alpha*A*A' + beta*C or alpha*A'*A + beta*C
according to whether trans is ÅeNÅf or ÅeTÅf. When uplo is ÅeUÅf the upper
triangle of C is updated (ÅeLÅf for lower triangle). Returns C.<br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
    </tr>
    <tr>
      <td style="vertical-align: top;">herk(uplo, trans, alpha, A) </td>
      <td style="vertical-align: top;">Methods for complex arrays only.
Returns either the
upper triangle or the lower triangle, according to uplo (ÅeUÅf or ÅeLÅf),
of alpha*A*A' or alpha*A'*A, according to trans (ÅeNÅf or ÅeTÅf).<br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
    </tr>
    <tr>
      <td style="vertical-align: top;">gbmv!(trans, m, kl, ku, alpha,
A, x, beta, y) </td>
      <td style="vertical-align: top;">Update vector y as alpha*A*x +
beta*y or alpha*A'*x
+ beta*y according to trans (ÅeNÅf or ÅeTÅf). The matrix A is a general
band matrix of dimension m by size(A,2) with kl sub-diagonals and ku
super-diagonals. Returns the updated y.<br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
    </tr>
    <tr>
      <td style="vertical-align: top;">gbmv(trans, m, kl, ku, alpha, A,
x, beta, y) </td>
      <td style="vertical-align: top;">Returns alpha*A*x or alpha*A'*x
according to trans
(ÅeNÅf or ÅeTÅf). The matrix A is a general band matrix of dimension m by
size(A,2) with kl sub-diagonals and ku super-diagonals.<br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
    </tr>
    <tr>
      <td style="vertical-align: top;">sbmv!(uplo, k, alpha, A, x,
beta, y) </td>
      <td style="vertical-align: top;">Update vector y as alpha*A*x +
beta*y where A is a a
symmetric band matrix of order size(A,2) with k super-diagonals stored
in the argument A. The storage layout for A is described the reference
BLAS module, level-2 BLAS at
&lt;http://www.netlib.org/lapack/explore-html/&gt;.<br>
Returns the updated y.<br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
    </tr>
    <tr>
      <td style="vertical-align: top;">sbmv(uplo, k, alpha, A, x) </td>
      <td style="vertical-align: top;">Returns alpha*A*x where A is a
symmetric band matrix
of order size(A,2) with k super-diagonals stored in the argument A.<br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
    </tr>
    <tr>
      <td style="vertical-align: top;">sbmv(uplo, k, A, x) </td>
      <td style="vertical-align: top;">Returns A*x where A is a
symmetric band matrix of
order size(A,2) with k super-diagonals stored in the argument A.<br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
    </tr>
    <tr>
      <td style="vertical-align: top;">gemm!(tA, tB, alpha, A, B, beta,
C) </td>
      <td style="vertical-align: top;">Update C as alpha*A*B + beta*C
or the other three
variants according to tA (transpose A) and tB. Returns the updated C.<br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
    </tr>
    <tr>
      <td style="vertical-align: top;">gemm(tA, tB, alpha, A, B) </td>
      <td style="vertical-align: top;">Returns alpha*A*B or the other
three variants
according to tA (transpose A) and tB.<br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
    </tr>
    <tr>
      <td style="vertical-align: top;">gemm(tA, tB, A, B) </td>
      <td style="vertical-align: top;">Returns A*B or the other three
variants according to
tA (transpose A) and tB.<br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
    </tr>
    <tr>
      <td style="vertical-align: top;">gemv!(tA, alpha, A, x, beta, y) </td>
      <td style="vertical-align: top;">Update the vector y as alpha*A*x
+ beta*y or
alpha*A'x + beta*y according to tA (transpose A). Returns the updated y.<br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
    </tr>
    <tr>
      <td style="vertical-align: top;">gemv(tA, alpha, A, x) </td>
      <td style="vertical-align: top;">Returns alpha*A*x or alpha*A'x
according to tA
(transpose A).<br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
    </tr>
    <tr>
      <td style="vertical-align: top;">gemv(tA, A, x) </td>
      <td style="vertical-align: top;">Returns A*x or A'x according to
tA (transpose A).<br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
    </tr>
    <tr>
      <td style="vertical-align: top;">symm!(side, ul, alpha, A, B,
beta, C) </td>
      <td style="vertical-align: top;">Update C as alpha*A*B + beta*C
or alpha*B*A + beta*C
according to side. A is assumed to be symmetric. Only the ul triangle
of A is used. Returns the updated C.<br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
    </tr>
    <tr>
      <td style="vertical-align: top;">symm(side, ul, alpha, A, B) </td>
      <td style="vertical-align: top;">Returns alpha*A*B or alpha*B*A
according to side. A
is assumed to be symmetric. Only the ul triangle of A is used.<br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
    </tr>
    <tr>
      <td style="vertical-align: top;">symm(side, ul, A, B) </td>
      <td style="vertical-align: top;">Returns A*B or B*A according to
side. A is assumed
to be symmetric. Only the ul triangle of A is used.<br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
    </tr>
    <tr>
      <td style="vertical-align: top;">symm(tA, tB, alpha, A, B) </td>
      <td style="vertical-align: top;">Returns alpha*A*B or the other
three variants
according to tA (transpose A) and tB.<br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
    </tr>
    <tr>
      <td style="vertical-align: top;">symv!(ul, alpha, A, x, beta, y) </td>
      <td style="vertical-align: top;">Update the vector y as alpha*A*x
+ beta*y. A is
assumed to be symmetric. Only the ul triangle of A is used. Returns the
updated y.<br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
    </tr>
    <tr>
      <td style="vertical-align: top;">symv(ul, alpha, A, x) </td>
      <td style="vertical-align: top;">Returns alpha*A*x. A is assumed
to be symmetric.
Only the ul triangle of A is used.<br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
    </tr>
    <tr>
      <td style="vertical-align: top;">symv(ul, A, x) </td>
      <td style="vertical-align: top;">Returns A*x. A is assumed to be
symmetric. Only the
ul triangle of A is used.<br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
    </tr>
    <tr>
      <td style="vertical-align: top;">trmm!(side, ul, tA, dA, alpha,
A, B) </td>
      <td style="vertical-align: top;">Update B as alpha*A*B or one of
the other three
variants determined by side (A on left or right) and tA (transpose A).
Only the ul triangle of A is used. dA indicates if A is unit-triangular
(the diagonal is assumed to be all ones). Returns the updated B.<br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
    </tr>
    <tr>
      <td style="vertical-align: top;">trmm(side, ul, tA, dA, alpha, A,
B) </td>
      <td style="vertical-align: top;">Returns alpha*A*B or one of the
other three variants
determined by side (A on left or right) and tA (transpose A). Only the
ul triangle of A is used. dA indicates if A is unit-triangular (the
diagonal is assumed to be all ones).<br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
    </tr>
    <tr>
      <td style="vertical-align: top;">rsm!(side, ul, tA, dA, alpha, A,
B) </td>
      <td style="vertical-align: top;">Overwrite B with the solution to
A*X = alpha*B or
one of the other three variants determined by side (A on left or right
of X) and tA (transpose A). Only the ul triangle of A is used. dA
indicates if A is unit-triangular (the diagonal is assumed to be all
ones). Returns the updated B.<br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
    </tr>
    <tr>
      <td style="vertical-align: top;">trsm(side, ul, tA, dA, alpha, A,
B) </td>
      <td style="vertical-align: top;">Returns the solution to A*X =
alpha*B or one of the
other three variants determined by side (A on left or right of X) and
tA (transpose A). Only the ul triangle of A is used. dA indicates if A
is unit-triangular (the diagonal is assumed to be all ones).<br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
    </tr>
    <tr>
      <td style="vertical-align: top;">trmv!(side, ul, tA, dA, alpha,
A, b) </td>
      <td style="vertical-align: top;">Update b as alpha*A*b or one of
the other three
variants determined by side (A on left or right) and tA (transpose A).
Only the ul triangle of A is used. dA indicates if A is unit-triangular
(the diagonal is assumed to be all ones). Returns the updated b.<br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
    </tr>
    <tr>
      <td style="vertical-align: top;">trmv(side, ul, tA, dA, alpha, A,
b) </td>
      <td style="vertical-align: top;">Returns alpha*A*b or one of the
other three variants
determined by side (A on left or right) and tA (transpose A). Only the
ul triangle of A is used. dA indicates if A is unit-triangular (the
diagonal is assumed to be all ones).<br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
    </tr>
    <tr>
      <td style="vertical-align: top;">trsv!(ul, tA, dA, A, b) </td>
      <td style="vertical-align: top;">Overwrite b with the solution to
A*x = b or one of
the other two variants determined by tA (transpose A) and ul (triangle
of A used). dA indicates if A is unit-triangular (the diagonal is
assumed to be all ones). Returns the updated b.<br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
    </tr>
    <tr>
      <td style="vertical-align: top;">rsv(ul, tA, dA, A, b) </td>
      <td style="vertical-align: top;">Returns the solution to A*x = b
or one of the other
two variants determined by tA (transpose A) and ul (triangle of A is
used.) dA indicates if A is unit-triangular (the diagonal is assumed to
be all ones).<br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
    </tr>
    <tr>
      <td style="vertical-align: top;">blas_set_num_threads(n) </td>
      <td style="vertical-align: top;">Set the number of threads the
BLAS library should
use.<br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
    </tr>
    <tr>
      <td style="vertical-align: top;">I<br>
      </td>
      <td style="vertical-align: top;">An object of type
UniformScaling, representing an identity matrix of any size.<br>
      </td>
      <td style="vertical-align: top;">I<br>
      </td>
      <td style="vertical-align: top;">UniformScaling{Int64}<br>
1*I</td>
    </tr>
  </tbody>
</table>
<br>
<br>
<br>
<br>
<table cellpadding="2" cellspacing="2" border="1"
 style="text-align: left; width: 100%;">
  <tbody>
    <tr>
      <td style="vertical-align: top;" rowspan="1" colspan="4">LAPACK
Functions<br>
      <a class="reference internal"
 href="file:///C:/Users/Saito/Desktop/Julia/%E3%83%9E%E3%83%8B%E3%83%A5%E3%82%A2%E3%83%AB/Julia%20Documentation/Standard%20Library/07_Linear%20Algebra/linalg.html#module-Base.LinAlg.LAPACK"
 title="Base.LinAlg.LAPACK"><code
 class="xref jl jl-mod docutils literal"><span class="pre">Base.LinAlg.LAPACK</span></code></a>
provides wrappers for some of the LAPACK functions for
linear algebra. Those functions that overwrite one of the input
arrays have names ending in <code class="docutils literal"><span
 class="pre">'!'</span></code>. <br>
Usually a function has 4 methods defined, one each for <code
 class="docutils literal"><span class="pre">Float64</span></code>, <code
 class="docutils literal"><span class="pre">Float32</span></code>, <code
 class="docutils literal"><span class="pre">Complex128</span></code>
and <code class="docutils literal"><span class="pre">Complex64</span></code>
arrays. <br>
Note that the LAPACK API provided by Julia can and will change in
the future. Since
this API is not user-facing, there is no commitment to
support/deprecate this specific
set of functions in future releases. </td>
    </tr>
    <tr>
      <td style="vertical-align: top; font-weight: bold;">èëéÆ<br>
      </td>
      <td style="vertical-align: top; font-weight: bold;">ã@î\<br>
      </td>
      <td style="vertical-align: top; font-weight: bold;">ó·ëË<br>
      </td>
      <td style="vertical-align: top; font-weight: bold;">åãâ <br>
      </td>
    </tr>
    <tr>
      <td style="vertical-align: top;">gbtrf!(kl, ku, m, AB) <br>
Å® (AB, ipiv) </td>
      <td style="vertical-align: top;">Compute the LU factorization of
a banded matrix AB.
kl is the first subdiagonal containing a nonzero band, ku is the last
superdiagonal containing one, and m is the first dimension of the
matrix AB. Returns the LU factorization in-place and ipiv, the vector
of pivots used.<br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
    </tr>
    <tr>
      <td style="vertical-align: top;">gbtrs!(trans, kl, ku, m, AB,
ipiv, B) </td>
      <td style="vertical-align: top;">Solve the equation AB * X = B.
trans determines the
orientation of AB. It may be N (no transpose), T (transpose), or C
(conjugate transpose). kl is the first subdiagonal containing a nonzero
band, ku is the last superdiagonal containing one, and m is the first
dimension of the matrix AB. ipiv is the vector of pivots returned from
gbtrf!. Returns the vector or matrix X, overwriting B in-place.<br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
    </tr>
    <tr>
      <td style="vertical-align: top;">gebal!(job, A) <br>
Å® (ilo, ihi,
scale) </td>
      <td style="vertical-align: top;">Balance the matrix A before
computing its
eigensystem or Schur factorization. job can be one of N (A will not be
permuted or scaled), P (A will only be permuted), S (A will only be
scaled), or B (A will be both permuted and scaled). Modifies A in-place
and returns ilo, ihi, and scale. If permuting was turned on, A[i,j] = 0
if j &gt; i and 1 &lt; j &lt; ilo or j &gt; ihi. scale contains
information about the scaling/permutations performed.<br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
    </tr>
    <tr>
      <td style="vertical-align: top;">gebak!(job, side, ilo, ihi,
scale, V) </td>
      <td style="vertical-align: top;">Transform the eigenvectors V of
a matrix balanced
using gebal! to the unscaled/unpermuted eigenvectors of the original
matrix. Modifies V in-place. side can be L (left eigenvectors are
transformed) or R (right eigenvectors are transformed).<br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
    </tr>
    <tr>
      <td style="vertical-align: top;">gebrd!(A)<br>
Å® (A, d, e, tauq,
taup) </td>
      <td style="vertical-align: top;">Reduce A in-place to bidiagonal
form A = QBP'.
Returns A, containing the bidiagonal matrix B; d, containing the
diagonal elements of B; e, containing the off-diagonal elements of B;
tauq, containing the elementary reflectors representing Q; and taup,
containing the elementary reflectors representing P.<br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
    </tr>
    <tr>
      <td style="vertical-align: top;">gelqf!(A, tau) </td>
      <td style="vertical-align: top;">Compute the LQ factorization of
A, A = LQ. tau
contains scalars which parameterize the elementary reflectors of the
factorization. tau must have length greater than or equal to the
smallest dimension of A.<br>
&nbsp;&nbsp;&nbsp; Returns A and tau modified in-place.<br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
    </tr>
    <tr>
      <td style="vertical-align: top;">gelqf!(A)<br>
Å® (A, tau) </td>
      <td style="vertical-align: top;">&nbsp;&nbsp;&nbsp; Compute the
LQ factorization of A, A = LQ.<br>
&nbsp;&nbsp;&nbsp; Returns A, modified in-place, and tau, which
contains scalars which parameterize the elementary reflectors of the
factorization.<br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
    </tr>
    <tr>
      <td style="vertical-align: top;">geqlf!(A, tau) </td>
      <td style="vertical-align: top;">&nbsp;&nbsp;&nbsp; Compute the
QL factorization of A, A = QL. tau
contains scalars which parameterize the elementary reflectors of the
factorization. tau must have length greater than or equal to the
smallest dimension of A.<br>
&nbsp;&nbsp;&nbsp; Returns A and tau modified in-place.<br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
    </tr>
    <tr>
      <td style="vertical-align: top;">geqlf!(A)<br>
Å® (A, tau) </td>
      <td style="vertical-align: top;">&nbsp;&nbsp;&nbsp; Compute the
QL factorization of A, A = QL.<br>
&nbsp;&nbsp;&nbsp; Returns A, modified in-place, and tau, which
contains scalars which parameterize the elementary reflectors of the
factorization.<br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
    </tr>
    <tr>
      <td style="vertical-align: top;">geqrf!(A, tau) </td>
      <td style="vertical-align: top;">&nbsp;&nbsp;&nbsp; Compute the
QR factorization of A, A = QR. tau
contains scalars which parameterize the elementary reflectors of the
factorization. tau must have length greater than or equal to the
smallest dimension of A.<br>
&nbsp;&nbsp;&nbsp; Returns A and tau modified in-place.<br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
    </tr>
    <tr>
      <td style="vertical-align: top;">geqrf!(A)Å® (A, tau) </td>
      <td style="vertical-align: top;">&nbsp;&nbsp;&nbsp; Compute the
QR factorization of A, A = QR.<br>
&nbsp;&nbsp;&nbsp; Returns A, modified in-place, and tau, which
contains scalars which parameterize the elementary reflectors of the
factorization.<br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
    </tr>
    <tr>
      <td style="vertical-align: top;">geqp3!(A, jpvt, tau) </td>
      <td style="vertical-align: top;">&nbsp;&nbsp;&nbsp; Compute the
pivoted QR factorization of A, AP = QR
using BLAS level 3. P is a pivoting matrix, represented by jpvt. tau
stores the elementary reflectors. jpvt must have length length greater
than or equal to n if A is an (m x n) matrix. tau must have length
greater than or equal to the smallest dimension of A.<br>
&nbsp;&nbsp;&nbsp; A, jpvt, and tau are modified in-place.<br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
    </tr>
    <tr>
      <td style="vertical-align: top;">geqp3!(A, jpvt)<br>
Å® (A, jpvt,
tau) </td>
      <td style="vertical-align: top;">&nbsp;&nbsp;&nbsp; Compute the
pivoted QR factorization of A, AP = QR
using BLAS level 3. P is a pivoting matrix, represented by jpvt. jpvt
must have length greater than or equal to n if A is an (m x n) matrix.<br>
&nbsp;&nbsp;&nbsp; Returns A and jpvt, modified in-place, and tau,
which stores the elementary reflectors.<br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
    </tr>
    <tr>
      <td style="vertical-align: top;">geqp3!(A)<br>
Å® (A, jpvt, tau) </td>
      <td style="vertical-align: top;">&nbsp;&nbsp;&nbsp; Compute the
pivoted QR factorization of A, AP = QR
using BLAS level 3.<br>
&nbsp;&nbsp;&nbsp; Returns A, modified in-place, jpvt, which represents
the pivoting matrix P, and tau, which stores the elementary reflectors.<br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
    </tr>
    <tr>
      <td style="vertical-align: top;">gerqf!(A, tau) </td>
      <td style="vertical-align: top;">&nbsp;&nbsp;&nbsp; Compute the
RQ factorization of A, A = RQ. tau
contains scalars which parameterize the elementary reflectors of the
factorization. tau must have length greater than or equal to the
smallest dimension of A.<br>
&nbsp;&nbsp;&nbsp; Returns A and tau modified in-place.<br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
    </tr>
    <tr>
      <td style="vertical-align: top;">gerqf!(A)<br>
Å® (A, tau) </td>
      <td style="vertical-align: top;">&nbsp;&nbsp;&nbsp; Compute the
RQ factorization of A, A = RQ.<br>
&nbsp;&nbsp;&nbsp; Returns A, modified in-place, and tau, which
contains scalars which parameterize the elementary reflectors of the
factorization.<br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
    </tr>
    <tr>
      <td style="vertical-align: top;">geqrt!(A, T) </td>
      <td style="vertical-align: top;">&nbsp;&nbsp;&nbsp; Compute the
blocked QR factorization of A, A = QR. T
contains upper triangular block reflectors which parameterize the
elementary reflectors of the factorization. The first dimension of T
sets the block size and it must be between 1 and n. The second
dimension of T must equal the smallest dimension of A.<br>
&nbsp;&nbsp;&nbsp; Returns A and T modified in-place.<br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
    </tr>
    <tr>
      <td style="vertical-align: top;">geqrt!(A, nb)<br>
Å® (A, T) </td>
      <td style="vertical-align: top;">&nbsp;&nbsp;&nbsp; Compute the
blocked QR factorization of A, A = QR.
nb sets the block size and it must be between 1 and n, the second
dimension of A.<br>
&nbsp;&nbsp;&nbsp; Returns A, modified in-place, and T, which contains
upper triangular block reflectors which parameterize the elementary
reflectors of the factorization.<br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
    </tr>
    <tr>
      <td style="vertical-align: top;">geqrt3!(A, T) </td>
      <td style="vertical-align: top;">&nbsp;&nbsp;&nbsp; Recursively
computes the blocked QR factorization of
A, A = QR. T contains upper triangular block reflectors which
parameterize the elementary reflectors of the factorization. The first
dimension of T sets the block size and it must be between 1 and n. The
second dimension of T must equal the smallest dimension of A.<br>
&nbsp;&nbsp;&nbsp; Returns A and T modified in-place.<br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
    </tr>
    <tr>
      <td style="vertical-align: top;">geqrt3!(A)<br>
Å® (A, T) </td>
      <td style="vertical-align: top;">&nbsp;&nbsp;&nbsp; Recursively
computes the blocked QR factorization of
A, A = QR.<br>
&nbsp;&nbsp;&nbsp; Returns A, modified in-place, and T, which contains
upper triangular block reflectors which parameterize the elementary
reflectors of the factorization.<br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
    </tr>
    <tr>
      <td style="vertical-align: top;">getrf!(A)<br>
Å® (A, ipiv, info) </td>
      <td style="vertical-align: top;">&nbsp;&nbsp;&nbsp; Compute the
pivoted LU factorization of A, A = LU.<br>
&nbsp;&nbsp;&nbsp; Returns A, modified in-place, ipiv, the pivoting
information, and an info code which indicates success (info = 0), a
singular value in U (info = i, in which case U[i,i] is singular), or an
error code (info &lt; 0).<br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
    </tr>
    <tr>
      <td style="vertical-align: top;">tzrzf!(A)<br>
Å® (A, tau) </td>
      <td style="vertical-align: top;">&nbsp;&nbsp;&nbsp; Transforms
the upper trapezoidal matrix A to upper
triangular form in-place. Returns A and tau, the scalar parameters for
the elementary reflectors of the transformation.<br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
    </tr>
    <tr>
      <td style="vertical-align: top;">ormrz!(side, trans, A, tau, C) </td>
      <td style="vertical-align: top;">&nbsp;&nbsp;&nbsp; Multiplies
the matrix C by Q from the transformation
supplied by tzrzf!. Depending on side or trans the multiplication can
be left-sided (side = L, Q*C) or right-sided (side = R, C*Q) and Q can
be unmodified (trans = N), transposed (trans = T), or conjugate
transposed (trans = C). Returns matrix C which is modified in-place
with the result of the multiplication.<br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
    </tr>
    <tr>
      <td style="vertical-align: top;">gels!(trans, A, B)<br>
Å® (F, B,
ssr) </td>
      <td style="vertical-align: top;">&nbsp;&nbsp;&nbsp; Solves the
linear equation A * X = B, A.' * X =B, or
A' * X = B using a QR or LQ factorization. Modifies the matrix/vector B
in place with the solution. A is overwritten with its QR or LQ
factorization. trans may be one of N (no modification), T (transpose),
or C (conjugate transpose). gels! searches for the minimum norm/least
squares solution. A may be under or over determined. The solution is
returned in B.<br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
    </tr>
    <tr>
      <td style="vertical-align: top;">gesv!(A, B)<br>
Å® (B, A, ipiv) </td>
      <td style="vertical-align: top;"><br>
      <br>
      <br>
&nbsp;&nbsp;&nbsp; Solves the linear equation A * X = B where A is a
square matrix using the LU factorization of A. A is overwritten with
its LU factorization and B is overwritten with the solution X. ipiv
contains the pivoting information for the LU factorization of A.<br>
      <br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
    </tr>
    <tr>
      <td style="vertical-align: top;">getrs!(trans, A, ipiv, B) </td>
      <td style="vertical-align: top;">&nbsp;&nbsp;&nbsp; Solves the
linear equation A * X = B, A.' * X =B, or
A' * X = B for square A. Modifies the matrix/vector B in place with the
solution. A is the LU factorization from getrf!, with ipiv the pivoting
information. trans may be one of N (no modification), T (transpose), or
C (conjugate transpose).<br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
    </tr>
    <tr>
      <td style="vertical-align: top;">getri!(A, ipiv) </td>
      <td style="vertical-align: top;">&nbsp;&nbsp;&nbsp; Computes the
inverse of A, using its LU
factorization found by getrf!. ipiv is the pivot information output and
A contains the LU factorization of getrf!. A is overwritten with its
inverse.<br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
    </tr>
    <tr>
      <td style="vertical-align: top;">gesvx!(fact, trans, A, AF, ipiv,
equed, R, C, B)<br>
Å® (X, equed, R, C,
B, rcond, ferr, berr, work) </td>
      <td style="vertical-align: top;">&nbsp;&nbsp;&nbsp; Solves the
linear equation A * X = B (trans = N),
A.' * X =B (trans = T), or A' * X = B (trans = C) using the LU
factorization of A. fact may be E, in which case A will be equilibrated
and copied to AF; F, in which case AF and ipiv from a previous LU
factorization are inputs; or N, in which case A will be copied to AF
and then factored. If fact = F, equed may be N, meaning A has not been
equilibrated; R, meaning A was multiplied by diagm(R) from the left; C,
meaning A was multiplied by diagm(C) from the right; or B, meaning A
was multiplied by diagm(R) from the left and diagm(C) from the right.
If fact = F and equed = R or B the elements of R must all be positive.
If fact = F and equed = C or B the elements of C must all be positive.<br>
&nbsp;&nbsp;&nbsp; Returns the solution X; equed, which is an output if
fact is not N, and describes the equilibration that was performed; R,
the row equilibration diagonal; C, the column equilibration diagonal;
B, which may be overwritten with its equilibrated form diagm(R)*B (if
trans = N and equed = R,B) or diagm(C)*B (if trans = T,C and equed =
C,B); rcond, the reciprocal condition number of A after equilbrating;
ferr, the forward error bound for each solution vector in X; berr, the
forward error bound for each solution vector in X; and work, the
reciprocal pivot growth factor.<br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
    </tr>
    <tr>
      <td style="vertical-align: top;">gesvx!(A, B) </td>
      <td style="vertical-align: top;">&nbsp;&nbsp;&nbsp; The
no-equilibration, no-transpose simplification of
gesvx!.<br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
    </tr>
    <tr>
      <td style="vertical-align: top;">gelsd!(A, B, rcond)<br>
Å® (B,
rnk) </td>
      <td style="vertical-align: top;">&nbsp;&nbsp;&nbsp; Computes the
least norm solution of A * X = B by
finding the SVD factorization of A, then dividing-and-conquering the
problem. B is overwritten with the solution X. Singular values below
rcond will be treated as zero. Returns the solution in B and the
effective rank of A in rnk.<br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
    </tr>
    <tr>
      <td style="vertical-align: top;">gelsy!(A, B, rcond)<br>
Å® (B,
rnk) </td>
      <td style="vertical-align: top;">&nbsp;&nbsp;&nbsp; Computes the
least norm solution of A * X = B by
finding the full QR factorization of A, then dividing-and-conquering
the problem. B is overwritten with the solution X. Singular values
below rcond will be treated as zero. Returns the solution in B and the
effective rank of A in rnk.<br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
    </tr>
    <tr>
      <td style="vertical-align: top;">gglse!(A, c, B, d)<br>
Å® (X,
res) </td>
      <td style="vertical-align: top;">&nbsp;&nbsp;&nbsp; Solves the
equation A * x = c where x is subject to
the equality constraint B * x = d. Uses the formula ||c - A*x||^2 = 0
to solve. Returns X and the residual sum-of-squares.<br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
    </tr>
    <tr>
      <td style="vertical-align: top;">geev!(jobvl, jobvr, A)<br>
Å® (W,
VL, VR) </td>
      <td style="vertical-align: top;">&nbsp;&nbsp;&nbsp; Finds the
eigensystem of A. If jobvl = N, the left
eigenvectors of A arenÅft computed. If jobvr = N, the right eigenvectors
of A arenÅft computed. If jobvl = V or jobvr = V, the corresponding
eigenvectors are computed. Returns the eigenvalues in W, the right
eigenvectors in VR, and the left eigenvectors in VL.<br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
    </tr>
    <tr>
      <td style="vertical-align: top;">gesdd!(job, A)<br>
Å® (U, S, VT) </td>
      <td style="vertical-align: top;">&nbsp;&nbsp;&nbsp; Finds the
singular value decomposition of A, A = U *
S * V', using a divide and conquer approach. If job = A, all the
columns of U and the rows of V' are computed. If job = N, no columns of
U or rows of V' are computed. If job = O, A is overwritten with the
columns of (thin) U and the rows of (thin) V'. If job = S, the columns
of (thin) U and the rows of (thin) V' are computed and returned
separately.<br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
    </tr>
    <tr>
      <td style="vertical-align: top;">gesvd!(jobu, jobvt, A)<br>
Å® (U,
S, VT) </td>
      <td style="vertical-align: top;">&nbsp;&nbsp;&nbsp; Finds the
singular value decomposition of A, A = U *
S * V'. If jobu = A, all the columns of U are computed. If jobvt = A
all the rows of V' are computed. If jobu = N, no columns of U are
computed. If jobvt = N no rows of V' are computed. If jobu = O, A is
overwritten with the columns of (thin) U. If jobvt = O, A is
overwritten with the rows of (thin) V'. If jobu = S, the columns of
(thin) U are computed and returned separately. If jobvt = S the rows of
(thin) V' are computed and returned separately. jobu and jobvt canÅft
both be O.<br>
&nbsp;&nbsp;&nbsp; Returns U, S, and Vt, where S are the singular
values of A.<br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
    </tr>
    <tr>
      <td style="vertical-align: top;">ggsvd!(jobu, jobv, jobq, A, B)<br>
Å® (U, V, Q, alpha, beta, k, l, R) </td>
      <td style="vertical-align: top;">&nbsp;&nbsp;&nbsp; Finds the
generalized singular value decomposition
of A and B, U'*A*Q = D1*R and V'*B*Q = D2*R. D1 has alpha on its
diagonal and D2 has beta on its diagonal. If jobu = U, the
orthogonal/unitary matrix U is computed. If jobv = V the
orthogonal/unitary matrix V is computed. If jobq = Q, the
orthogonal/unitary matrix Q is computed. If job{u,v,q} = N, that matrix
is not computed.<br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
    </tr>
    <tr>
      <td style="vertical-align: top;">geevx!(balanc, jobvl, jobvr,
sense, A)<br>
Å® (A, w, VL, VR, ilo, ihi,
scale, abnrm, rconde, rcondv) </td>
      <td style="vertical-align: top;">&nbsp;&nbsp;&nbsp; Finds the
eigensystem of A with matrix balancing. If
jobvl = N, the left eigenvectors of A arenÅft computed. If jobvr = N,
the right eigenvectors of A arenÅft computed. If jobvl = V or jobvr = V,
the corresponding eigenvectors are computed. If balanc = N, no
balancing is performed. If balanc = P, A is permuted but not scaled. If
balanc = S, A is scaled but not permuted. If balanc = B, A is permuted
and scaled. If sense = N, no reciprocal condition numbers are computed.
If sense = E, reciprocal condition numbers are computed for the
eigenvalues only. If sense = V, reciprocal condition numbers are
computed for the right eigenvectors only. If sense = B, reciprocal
condition numbers are computed for the right eigenvectors and the
eigenvectors. If sense = E,B, the right and left eigenvectors must be
computed.<br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
    </tr>
    <tr>
      <td style="vertical-align: top;">ggev!(jobvl, jobvr, A, B) Å®
(alpha, beta, vl, vr) </td>
      <td style="vertical-align: top;">&nbsp;&nbsp;&nbsp; Finds the
generalized eigendecomposition of A and B.
If jobvl = N, the left eigenvectors arenÅft computed. If jobvr = N, the
right eigenvectors arenÅft computed. If jobvl = V or jobvr = V, the
corresponding eigenvectors are computed.<br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
    </tr>
    <tr>
      <td style="vertical-align: top;">gtsv!(dl, d, du, B) </td>
      <td style="vertical-align: top;">&nbsp;&nbsp;&nbsp; Solves the
equation A * X = B where A is a
tridiagonal matrix with dl on the subdiagonal, d on the diagonal, and
du on the superdiagonal.<br>
&nbsp;&nbsp;&nbsp; Overwrites B with the solution X and returns it.<br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
    </tr>
    <tr>
      <td style="vertical-align: top;">gttrf!(dl, d, du) <br>
Å® (dl, d,
du, du2, ipiv) </td>
      <td style="vertical-align: top;">&nbsp;&nbsp;&nbsp; Finds the LU
factorization of a tridiagonal matrix
with dl on the subdiagonal, d on the diagonal, and du on the
superdiagonal.<br>
&nbsp;&nbsp;&nbsp; Modifies dl, d, and du in-place and returns them and
the second superdiagonal du2 and the pivoting vector ipiv.<br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
    </tr>
    <tr>
      <td style="vertical-align: top;">gttrs!(trans, dl, d, du, du2,
ipiv, B) </td>
      <td style="vertical-align: top;">&nbsp;&nbsp;&nbsp; Solves the
equation A * X = B (trans = N), A.' * X =
B (trans = T), or A' * X = B (trans = C) using the LU factorization
computed by gttrf!. B is overwritten with the solution X.<br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
    </tr>
    <tr>
      <td style="vertical-align: top;">orglq!(A, tau, k = length(tau)) </td>
      <td style="vertical-align: top;">&nbsp;&nbsp;&nbsp; Explicitly
finds the matrix Q of a LQ factorization
after calling gelqf! on A. Uses the output of gelqf!. A is overwritten
by Q.<br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
    </tr>
    <tr>
      <td style="vertical-align: top;">orgqr!(A, tau, k = length(tau)) </td>
      <td style="vertical-align: top;">&nbsp;&nbsp; Explicitly finds
the matrix Q of a QR factorization
after calling geqrf! on A. Uses the output of geqrf!. A is overwritten
by<br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
    </tr>
    <tr>
      <td style="vertical-align: top;">ormlq!(side, trans, A, tau, C) </td>
      <td style="vertical-align: top;">&nbsp;&nbsp;&nbsp; Computes Q *
C (trans = N), Q.' * C (trans = T), Q'
* C (trans = C) for side = L or the equivalent right-sided
multiplication for side = R using Q from a LQ factorization of A
computed using gelqf!. C is overwritten.<br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
    </tr>
    <tr>
      <td style="vertical-align: top;">ormqr!(side, trans, A, tau, C) </td>
      <td style="vertical-align: top;">&nbsp;&nbsp;&nbsp; Computes Q *
C (trans = N), Q.' * C (trans = T), Q'
* C (trans = C) for side = L or the equivalent right-sided
multiplication for side = R using Q from a QR factorization of A
computed using geqrf!. C is overwritten.<br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
    </tr>
    <tr>
      <td style="vertical-align: top;">gemqrt!(side, trans, V, T, C) </td>
      <td style="vertical-align: top;">&nbsp;&nbsp;&nbsp; Computes Q *
C (trans = N), Q.' * C (trans = T), Q'
* C (trans = C) for side = L or the equivalent right-sided
multiplication for side = R using Q from a QR factorization of A
computed using geqrt!. C is overwritten.<br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
    </tr>
    <tr>
      <td style="vertical-align: top;">posv!(uplo, A, B) <br>
Å® (A, B) </td>
      <td style="vertical-align: top;">&nbsp;&nbsp;&nbsp; Finds the
solution to A * X = B where A is a
symmetric or Hermitian positive definite matrix. If uplo = U the upper
Cholesky decomposition of A is computed. If uplo = L the lower Cholesky
decomposition of A is computed. A is overwritten by its Cholesky
decomposition. B is overwritten with the solution X.<br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
    </tr>
    <tr>
      <td style="vertical-align: top;">potrf!(uplo, A) </td>
      <td style="vertical-align: top;">&nbsp;&nbsp;&nbsp; Computes the
Cholesky (upper if uplo = U, lower if
uplo = L) decomposition of positive-definite matrix A. A is overwritten
and returned with an info code.<br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
    </tr>
    <tr>
      <td style="vertical-align: top;">potri!(uplo, A) </td>
      <td style="vertical-align: top;">&nbsp;&nbsp;&nbsp; Computes the
inverse of positive-definite matrix A
after calling potrf! to find its (upper if uplo = U, lower if uplo = L)
Cholesky decomposition.<br>
&nbsp;&nbsp;&nbsp; A is overwritten by its inverse and returned.<br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
    </tr>
    <tr>
      <td style="vertical-align: top;">potrs!(uplo, A, B) </td>
      <td style="vertical-align: top;">&nbsp;&nbsp;&nbsp; Finds the
solution to A * X = B where A is a
symmetric or Hermitian positive definite matrix whose Cholesky
decomposition was computed by potrf!. If uplo = U the upper Cholesky
decomposition of A was computed. If uplo = L the lower Cholesky
decomposition of A was computed. B is overwritten with the solution X.<br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
    </tr>
    <tr>
      <td style="vertical-align: top;">pstrf!(uplo, A, tol) <br>
Å® (A,
piv, rank, info) </td>
      <td style="vertical-align: top;">&nbsp;&nbsp;&nbsp; Computes the
(upper if uplo = U, lower if uplo = L)
pivoted Cholesky decomposition of positive-definite matrix A with a
user-set tolerance tol. A is overwritten by its Cholesky decomposition.<br>
&nbsp;&nbsp;&nbsp; Returns A, the pivots piv, the rank of A, and an
info code. If info = 0, the factorization succeeded. If info = i &gt; 0
`, then `A is indefinite or rank-deficient.<br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
    </tr>
    <tr>
      <td style="vertical-align: top;">ptsv!(D, E, B) </td>
      <td style="vertical-align: top;">&nbsp;&nbsp;&nbsp; Solves A * X
= B for positive-definite tridiagonal
A. D is the diagonal of A and E is the off-diagonal. B is overwritten
with the solution X and returned.<br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
    </tr>
    <tr>
      <td style="vertical-align: top;">pttrf!(D, E) </td>
      <td style="vertical-align: top;">&nbsp;&nbsp;&nbsp; Computes the
LDLt factorization of a
positive-definite tridiagonal matrix with D as diagonal and E as
off-diagonal. D and E are overwritten and returned.<br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
    </tr>
    <tr>
      <td style="vertical-align: top;">pttrs!(D, E, B) </td>
      <td style="vertical-align: top;">&nbsp;&nbsp;&nbsp; Solves A * X
= B for positive-definite tridiagonal A
with diagonal D and off-diagonal E after computing AÅes LDLt
factorization using pttrf!. B is overwritten with the solution X.<br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
    </tr>
    <tr>
      <td style="vertical-align: top;">trtri!(uplo, diag, A) </td>
      <td style="vertical-align: top;">Finds the inverse of (upper if
uplo = U, lower if
uplo = L) triangular matrix A. If diag = N, A has non-unit diagonal
elements. If diag = U, all diagonal elements of A are one. A is
overwritten with its inverse.<br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
    </tr>
    <tr>
      <td style="vertical-align: top;">trtrs!(uplo, trans, diag, A, B) </td>
      <td style="vertical-align: top;">Solves A * X = B (trans = N),
A.' * X = B (trans =
T), or A' * X = B (trans = C) for (upper if uplo = U, lower if uplo =
L) triangular matrix A. If diag = N, A has non-unit diagonal elements.
If diag = U, all diagonal elements of A are one. B is overwritten with
the solution X.<br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
    </tr>
    <tr>
      <td style="vertical-align: top;">trcon!(norm, uplo, diag, A) </td>
      <td style="vertical-align: top;">Finds the reciprocal condition
number of (upper if
uplo = U, lower if uplo = L) triangular matrix A. If diag = N, A has
non-unit diagonal elements. If diag = U, all diagonal elements of A are
one. If norm = I, the condition number is found in the infinity norm.
If norm = O or 1, the condition number is found in the one norm.<br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
    </tr>
    <tr>
      <td style="vertical-align: top;">trevc!(side, howmny, select, T,
VL = similar(T), VR = similar(T)) </td>
      <td style="vertical-align: top;">Finds the eigensystem of an
upper triangular matrix
T. If side = R, the right eigenvectors are computed. If side = L, the
left eigenvectors are computed. If side = B, both sets are computed. If
howmny = A, all eigenvectors are found. If howmny = B, all eigenvectors
are found and backtransformed using VL and VR. If howmny = S, only the
eigenvectors corresponding to the values in select are computed.<br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
    </tr>
    <tr>
      <td style="vertical-align: top;">trrfs!(uplo, trans, diag, A, B,
X, Ferr, Berr)<br>
&nbsp;Å® (Ferr, Berr) </td>
      <td style="vertical-align: top;">Estimates the error in the
solution to A * X = B
(trans = N), A.' * X = B (trans = T), A' * X = B (trans = C) for side =
L, or the equivalent equations a right-handed side = R X * A after
computing X using trtrs!. If uplo = U, A is upper triangular. If uplo =
L, A is lower triangular. If diag = N, A has non-unit diagonal
elements. If diag = U, all diagonal elements of A are one. Ferr and
Berr are optional inputs. Ferr is the forward error and Berr is the
backward error, each component-wise.<br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
    </tr>
    <tr>
      <td style="vertical-align: top;">stev!(job, dv, ev) <br>
Å® (dv,
Zmat) </td>
      <td style="vertical-align: top;">Computes the eigensystem for a
symmetric tridiagonal
matrix with dv as diagonal and ev as off-diagonal. If job = N only the
eigenvalues are found and returned in dv. If job = V then the
eigenvectors are also found and returned in Zmat.<br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
    </tr>
    <tr>
      <td style="vertical-align: top;">stebz!(range, order, vl, vu, il,
iu, abstol, dv, ev) <br>
Å® (dv, iblock,
isplit) </td>
      <td style="vertical-align: top;">Computes the eigenvalues for a
symmetric tridiagonal
matrix with dv as diagonal and ev as off-diagonal. If range = A, all
the eigenvalues are found. If range = V, the eigenvalues in the
half-open interval (vl, vu] are found. If range = I, the eigenvalues
with indices between il and iu are found. If order = B, eigvalues are
ordered within a block. If order = E, they are ordered across all the
blocks. abstol can be set as a tolerance for convergence.<br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
    </tr>
    <tr>
      <td style="vertical-align: top;">stegr!(jobz, range, dv, ev, vl,
vu, il, iu) Å® (w, Z) </td>
      <td style="vertical-align: top;">Computes the eigenvalues (jobz =
N) or eigenvalues
and eigenvectors (jobz = V) for a symmetric tridiagonal matrix with dv
as diagonal and ev as off-diagonal. If range = A, all the eigenvalues
are found. If range = V, the eigenvalues in the half-open interval (vl,
vu] are found. If range = I, the eigenvalues with indices between il
and iu are found. The eigenvalues are returned in w and the
eigenvectors in Z.<br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
    </tr>
    <tr>
      <td style="vertical-align: top;">stein!(dv, ev_in, w_in,
iblock_in, isplit_in) </td>
      <td style="vertical-align: top;">Computes the eigenvectors for a
symmetric
tridiagonal matrix with dv as diagonal and ev_in as off-diagonal. w_in
specifies the input eigenvalues for which to find corresponding
eigenvectors. iblock_in specifies the submatrices corresponding to the
eigenvalues in w_in. isplit_in specifies the splitting points between
the submatrix blocks.<br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
    </tr>
    <tr>
      <td style="vertical-align: top;">syconv!(uplo, A, ipiv) <br>
Å® (A,
work) </td>
      <td style="vertical-align: top;">Converts a symmetric matrix A
(which has been
factorized into a triangular matrix) into two matrices L and D. If uplo
= U, A is upper triangular. If uplo = L, it is lower triangular. ipiv
is the pivot vector from the triangular factorization. A is overwritten
by L and D.<br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
    </tr>
    <tr>
      <td style="vertical-align: top;">sysv!(uplo, A, B) <br>
Å® (B, A,
ipiv) </td>
      <td style="vertical-align: top;">Finds the solution to A * X = B
for symmetric matrix
A. If uplo = U, the upper half of A is stored. If uplo = L, the lower
half is stored. B is overwritten by the solution X. A is overwritten by
its Bunch-Kaufman factorization. ipiv contains pivoting information
about the factorization.<br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
    </tr>
    <tr>
      <td style="vertical-align: top;">sytrf!(uplo, A) <br>
Å® (A, ipiv) </td>
      <td style="vertical-align: top;">Computes the Bunch-Kaufman
factorization of a
symmetric matrix A. If uplo = U, the upper half of A is stored. If uplo
= L, the lower half is stored.<br>
Returns A, overwritten by the factorization, and a
pivot vector ipiv.<br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
    </tr>
    <tr>
      <td style="vertical-align: top;">sytri!(uplo, A, ipiv) </td>
      <td style="vertical-align: top;">Computes the inverse of a
symmetric matrix A using
the results of sytrf!. If uplo = U, the upper half of A is stored. If
uplo = L, the lower half is stored. A is overwritten by its inverse.<br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
    </tr>
    <tr>
      <td style="vertical-align: top;">sytrs!(uplo, A, ipiv, B) </td>
      <td style="vertical-align: top;">Solves the equation A * X = B
for a symmetric matrix
A using the results of sytrf!. If uplo = U, the upper half of A is
stored. If uplo = L, the lower half is stored. B is overwritten by the
solution X.<br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
    </tr>
    <tr>
      <td style="vertical-align: top;">hesv!(uplo, A, B) <br>
Å® (B, A,
ipiv) </td>
      <td style="vertical-align: top;">Finds the solution to A * X = B
for Hermitian matrix
A. If uplo = U, the upper half of A is stored. If uplo = L, the lower
half is stored. B is overwritten by the solution X. A is overwritten by
its Bunch-Kaufman factorization. ipiv contains pivoting information
about the factorization.<br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
    </tr>
    <tr>
      <td style="vertical-align: top;">hetrf!(uplo, A) <br>
Å® (A, ipiv) </td>
      <td style="vertical-align: top;">Computes the Bunch-Kaufman
factorization of a
Hermitian matrix A. If uplo = U, the upper half of A is stored. If uplo
= L, the lower half is stored.<br>
&nbsp;&nbsp;&nbsp; Returns A, overwritten by the factorization, and a
pivot vector.<br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
    </tr>
    <tr>
      <td style="vertical-align: top;">hetri!(uplo, A, ipiv) </td>
      <td style="vertical-align: top;">Computes the inverse of a
Hermitian matrix A using
the results of sytrf!. If uplo = U, the upper half of A is stored. If
uplo = L, the lower half is stored. A is overwritten by its inverse.<br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
    </tr>
    <tr>
      <td style="vertical-align: top;">hetrs!(uplo, A, ipiv, B) </td>
      <td style="vertical-align: top;">Solves the equation A * X = B
for a Hermitian matrix
A using the results of sytrf!. If uplo = U, the upper half of A is
stored. If uplo = L, the lower half is stored. B is overwritten by the
solution X.<br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
    </tr>
    <tr>
      <td style="vertical-align: top;">syev!(jobz, uplo, A) </td>
      <td style="vertical-align: top;">Finds the eigenvalues (jobz = N)
or eigenvalues and
eigenvectors (jobz = V) of a symmetric matrix A. If uplo = U, the upper
triangle of A is used. If uplo = L, the lower triangle of A is used.<br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
    </tr>
    <tr>
      <td style="vertical-align: top;">syevr!(jobz, range, uplo, A, vl,
vu, il, iu, abstol) <br>
Å® (W, Z) </td>
      <td style="vertical-align: top;">Finds the eigenvalues (jobz = N)
or eigenvalues and
eigenvectors (jobz = V) of a symmetric matrix A. If uplo = U, the upper
triangle of A is used. If uplo = L, the lower triangle of A is used. If
range = A, all the eigenvalues are found. If range = V, the eigenvalues
in the half-open interval (vl, vu] are found. If range = I, the
eigenvalues with indices between il and iu are found. abstol can be set
as a tolerance for convergence.<br>
&nbsp;&nbsp;&nbsp; The eigenvalues are returned in W and the
eigenvectors in Z.<br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
    </tr>
    <tr>
      <td style="vertical-align: top;">sygvd!(jobz, range, uplo, A, vl,
vu, il, iu, abstol) <br>
Å® (w, A, B) </td>
      <td style="vertical-align: top;">Finds the generalized
eigenvalues (jobz = N) or
eigenvalues and eigenvectors (jobz = V) of a symmetric matrix A and
symmetric positive-definite matrix B. If uplo = U, the upper triangles
of A and B are used. If uplo = L, the lower triangles of A and B are
used. If itype = 1, the problem to solve is A * x = lambda * B * x. If
itype = 2, the problem to solve is A * B * x = lambda * x. If itype =
3, the problem to solve is B * A * x = lambda * x.<br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
    </tr>
    <tr>
      <td style="vertical-align: top;">bdsqr!(uplo, d, e_, Vt, U, C) <br>
Å®
(d, Vt, U, C) </td>
      <td style="vertical-align: top;">Computes the singular value
decomposition of a
bidiagonal matrix with d on the diagonal and e_ on the off-diagonal. If
uplo = U, e_ is the superdiagonal. If uplo = L, e_ is the subdiagonal.
Can optionally also compute the product Q' * C.<br>
Returns the singular values in d, and the matrix C
overwritten with Q' * C.<br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
    </tr>
    <tr>
      <td style="vertical-align: top;">bdsdc!(uplo, compq, d, e_) <br>
Å®
(d, e, u, vt, q, iq) </td>
      <td style="vertical-align: top;">Computes the singular value
decomposition of a
bidiagonal matrix with d on the diagonal and e_ on the off-diagonal
using a divide and conqueq method. If uplo = U, e_ is the
superdiagonal. If uplo = L, e_ is the subdiagonal. If compq = N, only
the singular values are found. If compq = I, the singular values and
vectors are found. If compq = P, the singular values and vectors are
found in compact form. Only works for real types.<br>
&nbsp;&nbsp;&nbsp; Returns the singular values in d, and if compq = P,
the compact singular vectors in iq.<br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
    </tr>
    <tr>
      <td style="vertical-align: top;">gecon!(normtype, A, anorm) </td>
      <td style="vertical-align: top;">Finds the reciprocal condition
number of matrix A.
If normtype = I, the condition number is found in the infinity norm. If
normtype = O or 1, the condition number is found in the one norm. A
must be the result of getrf! and anorm is the norm of A in the relevant
norm.<br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
    </tr>
    <tr>
      <td style="vertical-align: top;">gehrd!(ilo, ihi, A) <br>
Å® (A,
tau) </td>
      <td style="vertical-align: top;">Converts a matrix A to
Hessenberg form. If A is
balanced with gebal! then ilo and ihi are the outputs of gebal!.
Otherwise they should be ilo = 1 and ihi = size(A,2). tau contains the
elementary reflectors of the factorization.<br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
    </tr>
    <tr>
      <td style="vertical-align: top;">orghr!(ilo, ihi, A, tau) </td>
      <td style="vertical-align: top;">Explicitly finds Q, the
orthogonal/unitary matrix
from gehrd!. ilo, ihi, A, and tau must correspond to the input/output
to gehrd!.<br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
    </tr>
    <tr>
      <td style="vertical-align: top;">gees!(jobvs, A) <br>
Å® (A, vs, w) </td>
      <td style="vertical-align: top;">Computes the eigenvalues (jobvs
= N) or the
eigenvalues and Schur vectors (jobvs = V) of matrix A. A is overwritten
by its Schur form.<br>
Returns A, vs containing the Schur vectors, and w,
containing the eigenvalues.<br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
    </tr>
    <tr>
      <td style="vertical-align: top;">gges!(jobvsl, jobvsr, A, B) Å®
(A, B, alpha, beta, vsl, vsr) </td>
      <td style="vertical-align: top;">Computes the generalized
eigenvalues, generalized
Schur form, left Schur vectors (jobsvl = V), or right Schur vectors
(jobvsr = V) of A and B.<br>
The generalized eigenvalues are returned in alpha
and beta. The left Schur vectors are returned in vsl and the right
Schur vectors are returned in vsr.<br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
    </tr>
    <tr>
      <td style="vertical-align: top;">trsen!(compq, job, select, T, Q)
Å® (T, Q, w) </td>
      <td style="vertical-align: top;">Reorder the Schur factorization
of a matrix and
optionally finds reciprocal condition numbers. If job = N, no condition
numbers are found. If job = E, only the condition number for this
cluster of eigenvalues is found. If job = V, only the condition number
for the invariant subspace is found. If job = B then the condition
numbers for the cluster and subspace are found. If compq = V the Schur
vectors Q are updated. If compq = N the Schur vectors are not modified.
select determines which eigenvalues are in the cluster.<br>
&nbsp;&nbsp;&nbsp; Returns T, Q, and reordered eigenvalues in w.<br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
    </tr>
    <tr>
      <td style="vertical-align: top;">tgsen!(select, S, T, Q, Z) Å®
(S, T, alpha, beta, Q, Z) </td>
      <td style="vertical-align: top;">Reorders the vectors of a
generalized Schur
decomposition. select specifices the eigenvalues in each cluster.<br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
    </tr>
    <tr>
      <td style="vertical-align: top;">trsyl!(transa, transb, A, B, C,
isgn=1) <br>
Å® (C, scale) </td>
      <td style="vertical-align: top;">Solves the Sylvester matrix
equation A * X +/- X * B
= scale*C where A and B are both quasi-upper triangular. If transa = N,
A is not modified. If transa = T, A is transposed. If transa = C, A is
conjugate transposed. Similarly for transb and B. If isgn = 1, the
equation A * X + X * B = scale * C is solved. If isgn = -1, the
equation A * X - X * B = scale * C is solved.<br>
&nbsp;&nbsp;&nbsp; Returns X (overwriting C) and scale.<br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
      <td style="vertical-align: top;"><br>
      </td>
    </tr>
  </tbody>
</table>
<br>
</body>
</html>
